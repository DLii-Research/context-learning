{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([\n",
    "    [0, 1, 1, 0], # XOR\n",
    "    [1, 0, 0, 1], # XNOR\n",
    "    [0, 0, 0, 1], # AND\n",
    "    [0, 1, 1, 1], # OR\n",
    "    [1, 0, 0, 0], # NOR\n",
    "    [1, 1, 1, 0], # NAND\n",
    "    [1, 0, 1, 0], # Custom 1\n",
    "    [0, 1, 0, 1]  # Custom 2\n",
    "])\n",
    "\n",
    "x_train = np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y, y_pred):\n",
    "    return tf.keras.losses.binary_crossentropy(y_true=y, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input((2,))\n",
    "x = Dense(40, activation=\"relu\")(inp)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_train\n",
    "y = labels[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_context_loss(context_layer_idx, gradients):\n",
    "        delta_at_next_layer = gradients[context_layer_idx + 1]\n",
    "        transpose_of_weights_at_next_layer = tf.transpose(model.layers[context_layer_idx + 1].get_weights()[0])\n",
    "        context_delta = np.dot(delta_at_next_layer, transpose_of_weights_at_next_layer).astype(np.float)\n",
    "        error = tf.keras.losses.mean_squared_error(np.zeros(len(context_delta)), context_delta)\n",
    "        return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gradients(x_train, y_train, batch_size):\n",
    "    # Calculate the total number of batches that need to be processed\n",
    "    context_loss = 0.0\n",
    "    grads = []\n",
    "    num_batches = int(np.ceil(len(x_train) / batch_size))\n",
    "\n",
    "    # Tensorflow 2 style training -- info can be found here: https://www.tensorflow.org/guide/effective_tf2 \n",
    "    # This is similar to model.fit(), however this is a custom training loop -- ie. it does things differently than model.fit()\n",
    "    # look at each input and label (there are 4 for the logic gates)\n",
    "    for start, end in ((s*batch_size, (s + 1)*batch_size) for s in range(num_batches)):\n",
    "\n",
    "        # Slice into batch\n",
    "        x = x_train[start:end]\n",
    "        y = y_train[start:end]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(x, training=True) # Forward pass\n",
    "            loss = loss_fn(y, predictions) # Get the loss\n",
    "\n",
    "        # Extract the gradients for the loss of the current sample\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        \n",
    "        grads.append(gradients)\n",
    "\n",
    "        context_loss += calc_context_loss(0, gradients)\n",
    "                \n",
    "    return context_loss, grads\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_loss, grads = calc_gradients(x, y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=5.1966925698251475e-08>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<tf.Tensor: shape=(2, 40), dtype=float32, numpy=\n",
       "array([[ 5.8108467e-06, -2.9225854e-05,  3.8266862e-05,  0.0000000e+00,\n",
       "         0.0000000e+00,  3.1838561e-06, -5.0916820e-05,  0.0000000e+00,\n",
       "         0.0000000e+00, -1.1877867e-05,  0.0000000e+00,  1.4344028e-05,\n",
       "         0.0000000e+00,  3.7515896e-05, -4.1118659e-05,  4.8243091e-05,\n",
       "        -3.0265262e-05,  0.0000000e+00, -3.9743773e-05, -3.6786765e-05,\n",
       "         0.0000000e+00,  3.6138696e-05,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  2.7895858e-05,\n",
       "         2.6317586e-05,  0.0000000e+00, -4.2991433e-06,  1.8742547e-05,\n",
       "         0.0000000e+00,  1.6616352e-05,  2.9790192e-05,  0.0000000e+00,\n",
       "        -2.9765752e-05,  0.0000000e+00,  0.0000000e+00, -4.2180283e-05],\n",
       "       [ 5.8108467e-06, -2.9225854e-05,  3.8266862e-05,  0.0000000e+00,\n",
       "         0.0000000e+00,  3.1838561e-06, -5.0916820e-05,  0.0000000e+00,\n",
       "         0.0000000e+00, -1.1877867e-05,  0.0000000e+00,  1.4344028e-05,\n",
       "         0.0000000e+00,  3.7515896e-05, -4.1118659e-05,  4.8243091e-05,\n",
       "        -3.0265262e-05,  0.0000000e+00, -3.9743773e-05, -3.6786765e-05,\n",
       "         0.0000000e+00,  3.6138696e-05,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  2.7895858e-05,\n",
       "         2.6317586e-05,  0.0000000e+00, -4.2991433e-06,  1.8742547e-05,\n",
       "         0.0000000e+00,  1.6616352e-05,  2.9790192e-05,  0.0000000e+00,\n",
       "        -2.9765752e-05,  0.0000000e+00,  0.0000000e+00, -4.2180283e-05]],\n",
       "      dtype=float32)>,\n",
       "       <tf.Tensor: shape=(40,), dtype=float32, numpy=\n",
       "array([-5.8108467e-06,  2.9225854e-05, -3.8266862e-05,  0.0000000e+00,\n",
       "        0.0000000e+00, -3.1838561e-06,  5.0916820e-05,  0.0000000e+00,\n",
       "        0.0000000e+00,  1.1877867e-05,  0.0000000e+00, -1.4344028e-05,\n",
       "        0.0000000e+00, -3.7515896e-05,  4.1118659e-05, -4.8243091e-05,\n",
       "        3.0265262e-05,  0.0000000e+00,  3.9743773e-05,  3.6786765e-05,\n",
       "        0.0000000e+00, -3.6138696e-05,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -2.7895858e-05,\n",
       "       -2.6317586e-05,  0.0000000e+00,  4.2991433e-06, -1.8742547e-05,\n",
       "        0.0000000e+00, -1.6616352e-05, -2.9790192e-05,  0.0000000e+00,\n",
       "        2.9765752e-05,  0.0000000e+00,  0.0000000e+00,  4.2180283e-05],\n",
       "      dtype=float32)>,\n",
       "       <tf.Tensor: shape=(40, 1), dtype=float32, numpy=\n",
       "array([[-6.32474912e-05],\n",
       "       [-1.93904689e-05],\n",
       "       [-2.97026563e-05],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [-1.69838040e-06],\n",
       "       [-4.77773901e-05],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [-7.20603930e-06],\n",
       "       [ 0.00000000e+00],\n",
       "       [-2.42913302e-05],\n",
       "       [ 0.00000000e+00],\n",
       "       [-3.65366286e-05],\n",
       "       [-2.75906791e-06],\n",
       "       [-9.37101777e-06],\n",
       "       [-6.92316860e-07],\n",
       "       [ 0.00000000e+00],\n",
       "       [-1.00202660e-05],\n",
       "       [-9.05631387e-05],\n",
       "       [ 0.00000000e+00],\n",
       "       [-1.13203760e-05],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [-6.16233447e-05],\n",
       "       [-7.70019979e-05],\n",
       "       [ 0.00000000e+00],\n",
       "       [-4.40872900e-05],\n",
       "       [-1.03519205e-05],\n",
       "       [ 0.00000000e+00],\n",
       "       [-8.40262783e-06],\n",
       "       [-8.56846527e-05],\n",
       "       [ 0.00000000e+00],\n",
       "       [-2.21071095e-05],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [-7.12965339e-05]], dtype=float32)>,\n",
       "       <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-0.00013706], dtype=float32)>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_grads = np.array(grads[0])\n",
    "for i in range(1, len(grads)):\n",
    "    total_grads = np.add(total_grads, grads[i]) / 2\n",
    "# total_grads /= len(grads)\n",
    "total_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
