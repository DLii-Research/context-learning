{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture Rewrite\n",
    "\n",
    "This notebook attempts to rewrite the NTaskModel class to utilize overridable methods to retain all Keras model properties and features.\n",
    "\n",
    "**Note** Due to what seems like some sort of bug in Keras, this rewrite is currently not possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.engine import data_adapter\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NTaskModel(Model):\n",
    "    \n",
    "    def compile(self, *args, **kwargs):\n",
    "        super(NTaskModel, self).compile(*args, **kwargs)\n",
    "        self.context_layers = []\n",
    "        self.my_test_count = 0\n",
    "        \n",
    "        \n",
    "    def _calc_context_loss(self, context_layer_idx, gradients):\n",
    "        \"\"\"\n",
    "        IMPORTANT: \n",
    "        1) Assumes no use of activation function on Ntask layer\n",
    "        2) Assumes that the layer following the Ntask layer:\n",
    "            a) Is a Dense layer\n",
    "            b) Is using bias \n",
    "               — ex: Dense(20, ... , use_bias=True) \n",
    "               — note Keras Dense layer uses bias by default if no value is given for use_bias param\n",
    "        3) Assumes index of the next layer's gradient is known within the gradients list returned from gradient tape in a tape.gradient call\n",
    "        4) If the above points aren't met, things will break and it may be hard to locate the bugs\n",
    "        \"\"\"\n",
    "        # From the delta rule in neural network math\n",
    "        delta_at_next_layer = gradients[context_layer_idx + 1]\n",
    "        transpose_of_weights_at_next_layer = tf.transpose(self.layers[context_layer_idx + 1].get_weights()[0])\n",
    "        \n",
    "        # Calculate delta at n-task layer\n",
    "        context_delta = np.dot(delta_at_next_layer, transpose_of_weights_at_next_layer).astype(np.float)\n",
    "        \n",
    "        # Calculate Context Error\n",
    "        # Keras MSE must have both args be arrs of floats, if one or both are arrs of ints, the output will be rounded to an int\n",
    "        # This is how responsible the context layer was for the loss\n",
    "        return tf.keras.losses.mean_squared_error(np.zeros(len(context_delta)), context_delta)\n",
    "    \n",
    "        \n",
    "    def _forward_pass(self, x, y, sample_weight=None):\n",
    "        \"\"\"\n",
    "        Performs a forward pass with active switching mechanism\n",
    "        x: input data\n",
    "        y: expected output (required for switching mechanisms)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Perform forward pass and calculate loss\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)\n",
    "            loss = self.compiled_loss(y, y_pred, sample_weight, regularization_losses=self.losses)\n",
    "            \n",
    "        # Extract the gradients for the loss of the current sample\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "\n",
    "        for context_layer_idx in self.context_layers:\n",
    "            self.layers[context_layer_idx].context_loss += self._calc_context_loss(context_layer_idx, gradients)\n",
    "        \n",
    "        # Return the calculated gradients\n",
    "        return y_pred, gradients\n",
    "    \n",
    "    \n",
    "    def train_step(self, batch):\n",
    "    \n",
    "        # Unpack the data\n",
    "        data = data_adapter.expand_1d(batch)\n",
    "        x, y, sample_weight = data_adapter.unpack_x_y_sample_weight(batch)\n",
    "    \n",
    "        # Perform a forward pass and calculate gradients\n",
    "        y_pred, gradients = self._forward_pass(x, y, sample_weight)\n",
    "        \n",
    "        # Apply the gradients to the model\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        # Update the metrics\n",
    "        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n",
    "        \n",
    "        self.my_test_count += 1\n",
    "        tf.print(\"Train step\", self.my_test_count)\n",
    "        \n",
    "        return {metric.name: metric.result() for metric in self.metrics}\n",
    "    \n",
    "    \n",
    "    def fit(self, *args, **kwargs):\n",
    "        # Method 1: Modify batch size here to size of dataset, divide in train step\n",
    "        return super(NTaskModel, self).fit(*args, **kwargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input((2,))\n",
    "x = Dense(40, activation=\"relu\")(inp)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = NTaskModel(inputs=inp, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss=tf.keras.losses.BinaryCrossentropy(), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([[1, 1], [-1, 1], [2, 2], [3, 3]]) # 4 inputs\n",
    "y_train = np.array([[1], [0], [2], [3]])              # 4 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step 2\n",
      "Train step 2\n",
      "Train step 2\n",
      "Train step 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdf04f210d0>"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=1, shuffle=False, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.my_test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.3652719 ],\n",
       "        [-0.14661784],\n",
       "        [ 0.1964958 ],\n",
       "        [-0.05448712],\n",
       "        [-0.0798344 ],\n",
       "        [ 0.07384975],\n",
       "        [ 0.23355207],\n",
       "        [ 0.16030094],\n",
       "        [ 0.24935973],\n",
       "        [-0.27872664],\n",
       "        [ 0.38130707],\n",
       "        [ 0.17336681],\n",
       "        [-0.10716698],\n",
       "        [-0.14784165],\n",
       "        [-0.22933787],\n",
       "        [-0.0591571 ],\n",
       "        [ 0.03553462],\n",
       "        [-0.20349382],\n",
       "        [ 0.07389298],\n",
       "        [-0.30909204],\n",
       "        [ 0.30697566],\n",
       "        [-0.03409614],\n",
       "        [-0.06402037],\n",
       "        [ 0.07586429],\n",
       "        [ 0.04679683],\n",
       "        [ 0.08286428],\n",
       "        [ 0.31718922],\n",
       "        [-0.1294789 ],\n",
       "        [-0.3269272 ],\n",
       "        [ 0.03682972],\n",
       "        [-0.24866512],\n",
       "        [ 0.19342953],\n",
       "        [ 0.35329303],\n",
       "        [ 0.37803873],\n",
       "        [-0.16188507],\n",
       "        [-0.02978953],\n",
       "        [ 0.01155861],\n",
       "        [ 0.23300216],\n",
       "        [-0.34957296],\n",
       "        [-0.25856268]], dtype=float32),\n",
       " array([0.00021756], dtype=float32)]"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[2].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
