{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Source\n",
    "\n",
    "This notebook experiments with re-implementing the model's source code inserting various event handlers for extension to n-task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Layer\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from collections import defaultdict\n",
    "from enum import IntFlag, auto\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "from utils import idx_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hrr(length, normalized=True):\n",
    "    \"\"\"Create a new HRR vector using Tensorflow tensors\"\"\"\n",
    "    length = int(length)      \n",
    "    shp = int((length-1)/2)\n",
    "    if normalized:    \n",
    "        x = tf.random.uniform( shape = (shp,), minval = -np.pi, maxval = np.pi, dtype = tf.dtypes.float32, seed = 100, name = None )\n",
    "        x = tf.cast(x, tf.complex64)\n",
    "        if length % 2:\n",
    "            x = tf.math.real( tf.signal.ifft( tf.concat([tf.ones(1, dtype=\"complex64\"), tf.exp(1j*x), tf.exp(-1j*x[::-1])], axis=0)))\n",
    "\n",
    "        else:  \n",
    "            x = tf.math.real(tf.signal.ifft(tf.concat([tf.ones(1, dtype=\"complex64\"),tf.exp(1j*x),tf.ones(1, dtype=\"complex64\"),tf.exp(-1j*x[::-1])],axis=0)))\n",
    "    else:        \n",
    "        x = tf.random.normal( shape = (length,), mean=0.0, stddev=1.0/tf.sqrt(float(length)),dtype=tf.dtypes.float32,seed=100,name=None)\n",
    "    return x\n",
    "\n",
    "\n",
    "def hrrs(length, n=1, normalized=True):\n",
    "    \"\"\"Create n new HRR vectors using Tensorflow tensors\"\"\"\n",
    "    return tf.stack([hrr(length, normalized) for x in range(n)], axis=0)\n",
    "\n",
    "\n",
    "def circ_conv(x, y):\n",
    "    \"\"\"Calculate the circular convolution between two HRR vectors\"\"\"\n",
    "    x = tf.cast(x, tf.complex64)\n",
    "    y = tf.cast(y, tf.complex64)\n",
    "    return tf.math.real(tf.signal.ifft(tf.signal.fft(x)*tf.signal.fft(y)))\n",
    "\n",
    "\n",
    "def logmod(x):\n",
    "    return np.sign(x)*np.log(abs(x) + 1)\n",
    "    \n",
    "    \n",
    "def plot(title, labels, *frameGroups):\n",
    "    fig, ax = plt.subplots()\n",
    "    plotFrames(ax, title, labels, *frameGroups, xlabel=\"Epoch\", ylabel=\"Value\")\n",
    "    ax.grid()\n",
    "    plt.legend()\n",
    "    \n",
    "    \n",
    "def plotFrames(ax, title, labels, *frameGroups, xlabel=None, ylabel=None):\n",
    "    for i, frames in enumerate(frameGroups):\n",
    "        keys = tuple(frames.keys() if type(frames) == dict else range(len(frames)))\n",
    "        t = np.arange(keys[0], keys[-1] + 1, 1)\n",
    "        ax.plot(t, list(frames.values()), label=(labels[i] if labels else None))\n",
    "    ax.set(xlabel=xlabel, ylabel=ylabel, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Verbosity(IntFlag):\n",
    "    Progress = auto()\n",
    "    Contexts = auto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtrModel:\n",
    "    \n",
    "    RESULT_UPDATED  = 0 # The ATR model was updated successfully\n",
    "    RESULT_SWITCHED = 1 # A task switch was triggered in the ATR\n",
    "    RESULT_ADDED    = 2 # A new task was added to the ATR model\n",
    "    \n",
    "    def __init__(self, switch_threshold, add_threshold=0.0, max_contexts=0):\n",
    "        \n",
    "        self.switch_threshold = tf.Variable(switch_threshold, name=\"Switch_Threshold\", trainable=False, dtype=tf.float32)\n",
    "        self.add_threshold = tf.Variable(add_threshold or 0.0, name=\"Add_Threshold\", trainable=False, dtype=tf.float32)\n",
    "        self._max_contexts = max_contexts\n",
    "        self._context_layer = None\n",
    "        \n",
    "        # Track the number of sequential switches so we can determine if no tasks fit the threshold\n",
    "        self._num_seq_switches = tf.Variable(0, name=\"Sequential_Switches\", trainable=False, dtype=tf.int64)\n",
    "        \n",
    "        # If we tried to add another context after the max number of contexts was reached, we should warn the user\n",
    "        # and stop checking whether or not a context should be added\n",
    "        self._exceeded_context_limit = tf.Variable(False, name=\"Context_Limit_Exceeded\", trainable=False, dtype=tf.bool)\n",
    "        \n",
    "        # To be built...\n",
    "        self.values = None\n",
    "        self.values_initialized = None\n",
    "        \n",
    "        \n",
    "    def set_context_layer(self, context_layer):\n",
    "        self._context_layer = context_layer\n",
    "    \n",
    "    \n",
    "    def build(self, num_contexts):\n",
    "        # Determine the number of contexts to create.\n",
    "        # Since we can't yet dynamically add contexts, we need\n",
    "        # to create the list at its max size initially.\n",
    "        num_contexts = max(num_contexts, self._max_contexts)\n",
    "        \n",
    "        # Create the list of ATR values to track\n",
    "        self.values = tf.Variable(np.zeros(num_contexts), name=\"ATR_Values\", trainable=False, dtype=tf.float32)\n",
    "        \n",
    "        # A second list is created to determine uninitialized ATR values\n",
    "        self.values_initialized = tf.Variable(np.zeros(num_contexts), name=\"ATR_Values_Initialized\", trainable=False, dtype=tf.bool)\n",
    "        \n",
    "    \n",
    "    def add_context(self):\n",
    "        # Add the new context to the context layer\n",
    "        self._context_layer.add_context()\n",
    "        \n",
    "        \n",
    "    def switch_contexts(self, context_loss, verbose):\n",
    "        \n",
    "        # If we have exhausted the context list, look for the one with the best fit\n",
    "        if self._num_seq_switches >= self.num_contexts:\n",
    "            best_fit = self.find_best_fit_context()\n",
    "            \n",
    "            # If no context really fits well and we can add more contexts, add a new one\n",
    "            if self.max_num_contexts > 0 and not self._exceeded_context_limit and self.should_add_context(context_loss, best_fit):\n",
    "                if self.num_contexts < self.max_num_contexts:\n",
    "                    self.add_context()\n",
    "                    self.hot_context = self.num_contexts - 1\n",
    "                    if verbose & Verbosity.Contexts:\n",
    "                        tf.print(f\"\\n[{self.context_layer.name}] Adding context {self.hot_context}\")\n",
    "                else:\n",
    "                    self._exceeded_context_limit.assign(True)\n",
    "                    tf.print(f\"\\n[{self.context_layer.name}] WARNING: Attempted to add context after context limit reached\")\n",
    "                \n",
    "            # Use the best fit context\n",
    "            else:\n",
    "                # Switch to the best-fitting context\n",
    "                self.hot_context = best_fit\n",
    "                \n",
    "                # Update the ATR value for the new context\n",
    "                self.update_atr_value(self.context_losses[self.hot_context], switched=True)\n",
    "\n",
    "        else:\n",
    "            self.context_layer.next_context()\n",
    "            if verbose & Verbosity.Contexts:\n",
    "                tf.print(f\"\\n[{self.context_layer.name}] Switching context to {self.hot_context}\")\n",
    "                \n",
    "    \n",
    "    def update_and_switch(self, context_loss, dynamic_switch, verbose):\n",
    "        \"\"\"\n",
    "        Update the ATR.\n",
    "        \n",
    "        Returns result type\n",
    "        \"\"\"\n",
    "        if dynamic_switch and self.should_switch(context_loss):\n",
    "            \n",
    "            # Count the switches\n",
    "            self._num_seq_switches.assign_add(1)\n",
    "            \n",
    "            # Switch contexts and return the result\n",
    "            return self.switch_contexts(context_loss, verbose)\n",
    "            \n",
    "        self.update_atr_value(context_loss, switched=False)\n",
    "            \n",
    "        # Reset the switch count if necessary\n",
    "        if self._num_seq_switches != 0:\n",
    "            self._num_seq_switches.assign(0)\n",
    "            \n",
    "        # Updated successfully\n",
    "        return AtrModel.RESULT_UPDATED\n",
    "    \n",
    "    \n",
    "    def set_atr_value(self, context_loss):\n",
    "        self.values.scatter_nd_update([[self.hot_context]], [context_loss])\n",
    "        if not self.values_initialized[self.hot_context]:\n",
    "            self.values_initialized.scatter_nd_update([[self.hot_context]], [True])\n",
    "            \n",
    "        \n",
    "    # Overridable ---------------------------------------------------------------------------------\n",
    "    \n",
    "    def context_loss_fn(self, context_delta):\n",
    "        # Calculate Context Error\n",
    "        # Keras MSE must have both args be arrs of floats, if one or both are arrs of ints, the output will be rounded to an int\n",
    "        # This is how responsible the context layer was for the loss\n",
    "        return tf.keras.losses.mean_squared_error(np.zeros(len(context_delta)), context_delta)\n",
    "        \n",
    "    def update_atr_value(self, context_loss, switched):\n",
    "        \"\"\"Update the ATR value\"\"\"\n",
    "        self.set_atr_value(context_loss)\n",
    "    \n",
    "    def find_best_fit_context(self):\n",
    "        \"\"\"Locate the context index with the best fit\"\"\"\n",
    "        return tf.argmax(tf.subtract(self.values, self.context_losses)[:self.num_contexts])\n",
    "    \n",
    "    def should_switch(self, context_loss):\n",
    "        # If the ATR value has not been initialized yet, we don't need to switch\n",
    "        if not self.values_initialized[self.hot_context]:\n",
    "            return False        \n",
    "        # If the context loss exceeds the threshold\n",
    "        delta = self.values[self.hot_context] - context_loss\n",
    "        return delta < self.switch_threshold\n",
    "    \n",
    "    def should_add_context(self, context_loss, best_fit_context_idx):\n",
    "        \"\"\"\n",
    "        Determine if a new context should be added\n",
    "        Note: This is only checked after a switch has been determined\n",
    "        \"\"\"\n",
    "        delta = self.values[self.hot_context] - self.context_losses[best_fit_context_idx]\n",
    "        return delta < self.add_threshold\n",
    "        \n",
    "    # Properties ----------------------------------------------------------------------------------\n",
    "        \n",
    "    @property\n",
    "    def context_losses(self):\n",
    "        return self.context_layer.context_losses\n",
    "        \n",
    "    @property\n",
    "    def num_contexts(self):\n",
    "        if self.context_layer is None:\n",
    "            return None\n",
    "        return self.context_layer.num_contexts\n",
    "        \n",
    "    @property\n",
    "    def max_num_contexts(self):\n",
    "        return self._max_contexts\n",
    "    \n",
    "    @property\n",
    "    def context_layer(self):\n",
    "        return self._context_layer\n",
    "    \n",
    "    @property\n",
    "    def hot_context(self):\n",
    "        return self._context_layer.hot_context\n",
    "    \n",
    "    @hot_context.setter\n",
    "    def hot_context(self, hot_context):\n",
    "        self._context_layer.hot_context = hot_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtrMovingAverage(AtrModel):\n",
    "    def update_atr_value(self, context_loss, switched):\n",
    "        if switched or not self.values_initialized[self.hot_context]:\n",
    "            self.set_atr_value(context_loss)\n",
    "        else:\n",
    "            self.set_atr_value((self.values[self.hot_context] + context_loss) / 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Context(Layer):\n",
    "    \n",
    "    def __init__(self, contexts=1, atr_model=None, **kwargs):\n",
    "        super(Context, self).__init__(**kwargs)\n",
    "        \n",
    "        # The ATR model handles the switching mechanisms\n",
    "        self._atr_model = atr_model\n",
    "        \n",
    "        # Information Tracking\n",
    "#         self._context_loss = tf.Variable([0.0, 0.0], name=\"Context_Losses\", trainable=False, dtype=float) # Created in build step\n",
    "        self._num_contexts = tf.Variable(contexts, name=\"Num_Contexts\", trainable=False, dtype=tf.int64)\n",
    "        self._hot_context = tf.Variable(0, name=\"Hot_Context\", trainable=False, dtype=tf.int64)\n",
    "        \n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # Store the input shape since weights can be rebuilt later\n",
    "        self._input_shape = int(input_shape[-1])\n",
    "        \n",
    "        # Build the ATR model\n",
    "        self._atr_model.set_context_layer(self)\n",
    "        self._atr_model.build(self.num_contexts)\n",
    "        \n",
    "        # The number of contexts to create in the kernel\n",
    "        num_kernel_contexts = max(self.num_contexts, self.atr_model.max_num_contexts)\n",
    "        \n",
    "        # Create the HRR initializer. This will create the list of HRR vectors\n",
    "        initializer = lambda shape, dtype=None: hrrs(self._input_shape, n=num_kernel_contexts)\n",
    "        self.kernel = self.add_weight(name=\"context\", shape=[num_kernel_contexts, self._input_shape], initializer=initializer, trainable=False)\n",
    "        \n",
    "        # Store the context losses for each context\n",
    "        self._context_loss = tf.Variable(np.zeros(num_kernel_contexts), name=\"Context_Losses\", trainable=False, dtype=float)\n",
    "        \n",
    "        #TEMP\n",
    "        self._max_contexts = num_kernel_contexts\n",
    "        \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Calculate the output for this layer.\n",
    "        \n",
    "        This layer convolves the input values with the context HRR vector\n",
    "        to produce the output tensor.\n",
    "        \"\"\"\n",
    "        # Fetch the hot context's HRR vector\n",
    "        context_hrr = self.kernel[self.hot_context]\n",
    "        \n",
    "        # Return the resulting convolution between the inputs and the context HRR\n",
    "        return circ_conv(inputs, context_hrr)\n",
    "    \n",
    "    \n",
    "    def update_and_switch(self, dynamic_switch, verbose):\n",
    "        \"\"\"\n",
    "        Update ATR values and switch contexts if necessary.\n",
    "        Returns True if no context switch occurs; False otherwise\n",
    "        \"\"\"\n",
    "        # If there is no ATR model, there's nothing to update\n",
    "        if self._atr_model is None:\n",
    "            return True\n",
    "        \n",
    "        # Update the ATR madel\n",
    "        result = self._atr_model.update_and_switch(self.context_loss, dynamic_switch, verbose)\n",
    "        \n",
    "        # Clear the context loss when we're done\n",
    "        \n",
    "        self.clear_context_loss()\n",
    "        \n",
    "        # Did the ATR model update or switch?\n",
    "        return result == AtrModel.RESULT_UPDATED\n",
    "        \n",
    "    \n",
    "    #TODO Context adding\n",
    "    def add_context(self):\n",
    "        # kernel_arr = self.kernel.value()\n",
    "        # num_hrrs = max(0, self._num_contexts - len(kernel_arr))\n",
    "        # initializer = lambda shape, dtype=None: np.append(kernel_arr[:self.num_contexts], hrrs(self._input_shape, n=num_hrrs), axis=0)\n",
    "        # new_weights = self.add_weight(name=\"context\", shape=[self.num_contexts, self._input_shape], initializer=initializer, trainable=False)\n",
    "        # Create the weights for the layer.\n",
    "        # The weights in this layer are generated HRR vectors, and are never updated.\n",
    "        # self.kernel = new_weights\n",
    "        \n",
    "        if self._num_contexts < self._max_contexts:\n",
    "            self._num_contexts.assign_add(1)\n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "    \n",
    "    def clear_context_loss(self):\n",
    "        \"\"\"Clear the context loss for the current epoch\"\"\"\n",
    "        self._context_loss.scatter_nd_update([[self.hot_context]], [0.0])\n",
    "    \n",
    "    \n",
    "    def add_context_loss(self, context_loss):\n",
    "        \"\"\"Accumulate context loss\"\"\"\n",
    "        if self._atr_model is not None:\n",
    "            context_loss = self._atr_model.context_loss_fn(context_loss)\n",
    "        else:\n",
    "            context_loss = tf.keras.losses.mean_squared_error(np.zeros(len(context_loss)), context_loss)\n",
    "        self._context_loss.scatter_nd_add([[self.hot_context]], [context_loss])\n",
    "        \n",
    "        \n",
    "    def next_context(self):\n",
    "        \"\"\"Switch to the next sequential context\"\"\"\n",
    "        self.hot_context = (self.hot_context + 1) % self.num_contexts\n",
    "        \n",
    "    \n",
    "    @property\n",
    "    def atr_model(self):\n",
    "        return self._atr_model\n",
    "    \n",
    "    @property\n",
    "    def context_loss(self):\n",
    "        return self._context_loss[self.hot_context]\n",
    "    \n",
    "    @property\n",
    "    def context_losses(self):\n",
    "        return self._context_loss\n",
    "        \n",
    "    @property\n",
    "    def num_contexts(self):\n",
    "        return self._num_contexts.value()\n",
    "    \n",
    "    @property\n",
    "    def hot_context(self):\n",
    "        \"\"\"Get the active context index\"\"\"\n",
    "        return self._hot_context.value()\n",
    "    \n",
    "    @hot_context.setter\n",
    "    def hot_context(self, hot_context):\n",
    "        if hot_context not in range(self.num_contexts):\n",
    "            raise ValueError(\"`Provided context does not exist\")\n",
    "        self._hot_context.assign(hot_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"n_task_model_170\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_184 (InputLayer)       [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense_355 (Dense)            (None, 128)               384       \n",
      "_________________________________________________________________\n",
      "context_178 (Context)        (None, 128)               260       \n",
      "_________________________________________________________________\n",
      "dense_356 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 773\n",
      "Trainable params: 513\n",
      "Non-trainable params: 260\n",
      "_________________________________________________________________\n",
      "[array([[ 5.43071777e-02,  1.28227025e-02,  1.11051008e-01,\n",
      "         3.64720821e-03, -6.69622868e-02, -7.75132477e-02,\n",
      "         8.23460668e-02, -1.00316785e-01, -1.98814690e-01,\n",
      "        -1.28059357e-01, -9.55704376e-02, -1.52470648e-01,\n",
      "        -1.01731040e-01, -8.28238577e-02, -8.36074799e-02,\n",
      "        -4.26056981e-02, -8.08065236e-02,  1.73879042e-01,\n",
      "         1.25318155e-01,  1.10034749e-01,  4.97369915e-02,\n",
      "        -1.99193299e-01,  1.86092719e-01,  1.13830611e-01,\n",
      "         1.04083583e-01, -2.02551112e-01, -6.59714192e-02,\n",
      "        -2.21817195e-02, -1.36358291e-02,  1.88025340e-01,\n",
      "        -1.90332532e-04,  1.54176310e-01,  2.58163810e-02,\n",
      "         4.66559976e-02,  3.06129158e-02,  3.35227102e-02,\n",
      "         2.14466855e-01,  1.40750408e-02, -1.94361001e-01,\n",
      "        -6.55268282e-02, -7.14548379e-02,  1.69611439e-01,\n",
      "         1.90209016e-01,  1.92152336e-01, -1.69082090e-01,\n",
      "         5.02996296e-02,  1.46247044e-01,  8.87801796e-02,\n",
      "         4.21200842e-02, -2.01982468e-01, -2.13846266e-01,\n",
      "         4.22904342e-02, -1.92302153e-01,  4.15013283e-02,\n",
      "         1.34707943e-01, -5.40428311e-02,  3.23033035e-02,\n",
      "        -8.43812674e-02, -2.32509375e-02,  5.86669147e-03,\n",
      "         2.16603428e-02, -1.40138298e-01,  1.53099135e-01,\n",
      "         1.30109474e-01,  9.82202142e-02, -7.25492686e-02,\n",
      "        -1.52401045e-01,  2.81561315e-02, -1.97541296e-01,\n",
      "         4.49345857e-02,  1.66629896e-01, -6.32270873e-02,\n",
      "         6.71698898e-02,  1.40791550e-01, -3.56058031e-02,\n",
      "         3.14155519e-02, -5.89543581e-03,  2.16064006e-02,\n",
      "         1.42750636e-01, -1.47947267e-01,  1.63084432e-01,\n",
      "        -5.80430031e-02,  1.72504038e-02,  6.51816577e-02,\n",
      "        -1.21715240e-01,  1.85059294e-01,  7.00960606e-02,\n",
      "         8.03519040e-02,  1.74351633e-02,  2.04334244e-01,\n",
      "        -4.92510498e-02,  3.47300321e-02, -8.48361552e-02,\n",
      "        -8.02025348e-02, -2.01292470e-01, -1.82134151e-01,\n",
      "         1.91770926e-01, -2.04219729e-01,  1.99556723e-01,\n",
      "        -1.38953298e-01,  1.37825027e-01,  2.04098091e-01,\n",
      "        -5.49166054e-02, -6.51067197e-02, -1.53090224e-01,\n",
      "         1.35356292e-01,  1.85488746e-01, -1.10275440e-01,\n",
      "         9.41018313e-02, -1.04589604e-01, -1.12358376e-01,\n",
      "         3.16299498e-02, -2.94352621e-02, -3.49154472e-02,\n",
      "        -1.50641888e-01, -1.94876194e-02, -3.31619680e-02,\n",
      "        -2.89303809e-02, -1.24166861e-01, -1.95170760e-01,\n",
      "        -1.92134455e-01,  1.27797589e-01, -1.01145282e-01,\n",
      "         9.46089625e-04,  1.29737332e-01,  1.77705571e-01,\n",
      "         2.28004605e-02, -1.52315974e-01],\n",
      "       [ 2.07462162e-02,  7.81527907e-02, -3.53266001e-02,\n",
      "        -1.35117084e-01,  1.57594398e-01,  5.27770817e-03,\n",
      "         1.17082402e-01, -5.85303158e-02,  1.36448160e-01,\n",
      "        -5.13613820e-02,  1.45909771e-01,  1.44007549e-01,\n",
      "        -1.01613402e-02, -6.15386516e-02,  8.87894481e-02,\n",
      "        -2.06134975e-01, -1.27451569e-02, -5.61397523e-02,\n",
      "         3.86076719e-02,  1.95426092e-01, -1.89327061e-01,\n",
      "         6.24319762e-02,  3.23933959e-02, -2.09800512e-01,\n",
      "        -1.83881909e-01,  1.14101470e-02,  7.58220404e-02,\n",
      "         1.47735164e-01, -1.50178373e-03,  1.74127206e-01,\n",
      "        -1.90878525e-01,  2.09915593e-01, -2.13324845e-01,\n",
      "         4.09699827e-02, -1.39708608e-01,  7.03313202e-02,\n",
      "         1.74564108e-01, -1.25928894e-01, -2.38852054e-02,\n",
      "         9.38070565e-02,  1.88510612e-01,  1.66389123e-01,\n",
      "        -3.77846658e-02, -2.07920358e-01, -2.10639298e-01,\n",
      "        -2.01360092e-01,  1.66053921e-02,  1.42446801e-01,\n",
      "        -9.68814269e-02,  1.87811032e-01,  6.64551407e-02,\n",
      "         1.24580577e-01,  1.93601623e-01,  3.91663462e-02,\n",
      "        -2.96066999e-02,  1.40530273e-01, -9.45623666e-02,\n",
      "         5.13895601e-02,  1.29664913e-01,  1.57385930e-01,\n",
      "        -1.29851103e-01, -9.63250175e-02, -1.49906516e-01,\n",
      "        -1.27438262e-01,  2.76653320e-02, -5.79106957e-02,\n",
      "         5.30613959e-03, -1.38810188e-01, -9.56577659e-02,\n",
      "        -1.84507355e-01, -1.64032713e-01,  1.77082315e-01,\n",
      "         3.69146317e-02, -9.07329172e-02,  6.97688609e-02,\n",
      "         9.69160646e-02,  1.03331789e-01, -2.66606361e-02,\n",
      "         2.06138149e-01,  1.62357762e-01,  7.35640079e-02,\n",
      "         2.28715092e-02,  1.16056845e-01,  1.37307242e-01,\n",
      "        -9.76088643e-03, -7.20995069e-02,  1.56571671e-01,\n",
      "         2.13812247e-01,  1.45426914e-01,  1.76592156e-01,\n",
      "        -2.03824818e-01,  6.57270998e-02, -1.73000097e-01,\n",
      "        -1.33084208e-01,  1.96671113e-01, -1.69617802e-01,\n",
      "        -1.86234817e-01, -8.14254731e-02,  7.87823051e-02,\n",
      "         8.81710202e-02,  6.86353594e-02, -1.15253769e-01,\n",
      "         1.24612793e-01,  6.23877794e-02,  3.06643546e-02,\n",
      "         1.96263447e-01,  1.99620381e-01, -1.90849751e-02,\n",
      "         7.73361474e-02, -8.55451971e-02, -3.93855572e-03,\n",
      "        -9.82963964e-02,  1.05339140e-02, -1.42135277e-01,\n",
      "         3.39506567e-02, -1.39239669e-01,  2.08776891e-02,\n",
      "         2.07031369e-02, -1.43115848e-01,  4.29480523e-02,\n",
      "         1.34449080e-01, -5.39049506e-04,  9.27376300e-02,\n",
      "         1.85997322e-01, -7.61019737e-02, -3.31356823e-02,\n",
      "        -1.68289915e-01, -5.60685992e-02]], dtype=float32),\n",
      " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
      " 2,\n",
      " 0,\n",
      " array([[ 1.87126040e-01, -9.17303711e-02,  6.24253750e-02,\n",
      "        -4.24941629e-03,  1.97412893e-01,  9.08260047e-02,\n",
      "         4.00166996e-02,  1.82109132e-01, -5.83498664e-02,\n",
      "         1.69494838e-01,  9.69033986e-02, -1.36146411e-01,\n",
      "        -2.05125660e-03, -8.25174153e-04, -1.09269246e-01,\n",
      "        -9.59316343e-02, -3.13896686e-03,  2.01940425e-02,\n",
      "        -7.74421394e-02,  1.81244574e-02, -7.31965229e-02,\n",
      "        -1.17506117e-01,  1.46662742e-02, -8.39441866e-02,\n",
      "         3.91963981e-02,  9.02598128e-02, -1.11897908e-01,\n",
      "         1.00678541e-02, -1.04093231e-01, -7.67275915e-02,\n",
      "         1.29501924e-01,  1.18789300e-02,  6.57437220e-02,\n",
      "        -1.23697147e-03, -2.76391618e-02,  1.03657886e-01,\n",
      "         5.25156371e-02, -9.75008085e-02, -5.54900430e-02,\n",
      "         6.03931397e-02,  2.51755975e-02,  1.57103449e-01,\n",
      "        -5.03201783e-03, -2.05607399e-01,  1.81895159e-02,\n",
      "        -7.03016222e-02,  6.44081384e-02,  2.41748393e-02,\n",
      "        -1.56384557e-02,  9.60165411e-02,  1.55535966e-01,\n",
      "        -8.51866156e-02,  3.32155898e-02, -7.81464726e-02,\n",
      "         1.07427731e-01, -2.81482488e-02,  6.46335408e-02,\n",
      "        -9.73679572e-02, -8.72042924e-02,  2.57214289e-02,\n",
      "         1.46108896e-01, -1.18786611e-01, -4.50034328e-02,\n",
      "        -7.46221244e-02, -7.06524402e-03, -3.72598134e-02,\n",
      "        -5.29471189e-02,  6.41831160e-02,  1.56111613e-01,\n",
      "        -8.43145847e-02, -1.21231824e-01,  1.50500789e-01,\n",
      "         1.75158419e-02,  1.18819624e-03,  9.52801108e-02,\n",
      "        -4.78591025e-03, -8.58289823e-02, -9.48972553e-02,\n",
      "         6.19314313e-02, -2.15296485e-02, -4.15927172e-02,\n",
      "        -8.06674808e-02, -6.88795894e-02, -1.21301021e-02,\n",
      "         8.12284127e-02, -5.15614823e-03,  1.36944428e-01,\n",
      "         1.44491903e-02,  7.43372887e-02, -8.17579702e-02,\n",
      "         1.35500357e-02, -6.37338907e-02, -9.85821858e-02,\n",
      "        -1.41811594e-02,  8.44901651e-02,  2.60497898e-01,\n",
      "        -2.42029950e-02, -8.85245055e-02, -1.13276362e-01,\n",
      "         3.01761180e-03, -1.70527026e-01,  4.60394695e-02,\n",
      "         7.36909658e-02,  7.67497532e-03, -4.41959091e-02,\n",
      "         1.24436356e-01,  9.61717963e-02,  1.70424268e-01,\n",
      "         7.05550909e-02,  5.31120375e-02, -3.49107459e-02,\n",
      "        -1.42308213e-02,  9.84831974e-02, -1.41212106e-01,\n",
      "        -6.12079278e-02,  1.69291385e-02,  4.53575477e-02,\n",
      "         1.46692060e-02, -4.81956303e-02,  1.86058268e-01,\n",
      "        -2.05083042e-02,  4.30283844e-02, -3.19463015e-03,\n",
      "        -9.57099162e-03,  1.10245429e-01,  2.99638584e-02,\n",
      "         5.56970946e-02, -2.82769632e-02],\n",
      "       [ 5.45557365e-02, -3.22965309e-02, -6.55206516e-02,\n",
      "         6.82531074e-02,  1.41418159e-01, -5.34796268e-02,\n",
      "        -1.55914143e-01,  2.05076918e-01, -8.90447944e-02,\n",
      "        -8.91164914e-02, -5.33849560e-02,  3.49304080e-02,\n",
      "        -2.91176867e-02,  4.26241904e-02, -3.78159694e-02,\n",
      "        -2.31481977e-02,  8.86219889e-02,  1.63862258e-02,\n",
      "        -6.66330755e-03, -1.03951074e-01, -1.34134814e-02,\n",
      "        -3.41283903e-03,  8.31202120e-02,  6.60121664e-02,\n",
      "         3.42572369e-02,  1.74553394e-02,  6.67457655e-03,\n",
      "        -1.15295872e-04,  1.26278698e-01, -1.19784296e-01,\n",
      "        -1.88793652e-02,  1.68220714e-01,  4.86158170e-02,\n",
      "         1.62486479e-01, -4.19521257e-02, -1.28675148e-01,\n",
      "         4.37619463e-02, -5.05153835e-03,  1.75288484e-01,\n",
      "         2.47520991e-02, -1.94232855e-02, -1.01065129e-01,\n",
      "         2.20985398e-01, -9.11887363e-03, -2.97381394e-02,\n",
      "        -1.40811205e-01,  1.32040158e-01, -8.85328948e-02,\n",
      "         3.90143320e-02,  5.73887378e-02,  1.04689494e-01,\n",
      "         4.96798605e-02, -1.70387533e-02, -2.97895875e-02,\n",
      "        -5.62961884e-02, -1.80372372e-02, -1.48234665e-02,\n",
      "        -7.46409744e-02,  1.05625987e-02,  1.35159016e-01,\n",
      "         2.25526728e-02,  1.48002818e-01, -5.76089062e-02,\n",
      "        -5.21724895e-02, -1.02478124e-01, -1.81769021e-03,\n",
      "         1.67939425e-01, -2.46253312e-02,  5.26726097e-02,\n",
      "         5.86827099e-02, -1.34134144e-02,  1.50791556e-02,\n",
      "         7.89111704e-02,  5.98256066e-02,  1.10573381e-01,\n",
      "         7.31995795e-03, -5.51858917e-02, -2.26696447e-01,\n",
      "        -1.59837350e-01,  5.38725741e-02,  9.65495259e-02,\n",
      "        -1.69289783e-01,  1.60808295e-01, -6.06449023e-02,\n",
      "        -1.48449600e-01, -2.59272791e-02, -1.00071147e-01,\n",
      "        -3.08208019e-02,  6.87580183e-03, -1.12787515e-01,\n",
      "        -5.01048490e-02,  3.37868780e-02,  1.32913291e-01,\n",
      "        -9.42883268e-03,  8.86646062e-02, -2.16229111e-02,\n",
      "         5.09058945e-02,  7.24672526e-02, -2.66838726e-02,\n",
      "         3.07067893e-02, -9.67582986e-02, -1.29785702e-01,\n",
      "        -1.05386660e-01, -8.98784250e-02, -8.03681388e-02,\n",
      "         2.20981240e-03, -3.58569473e-02,  1.02131702e-02,\n",
      "        -5.46686314e-02,  6.78710267e-02,  1.17701575e-01,\n",
      "         1.54684745e-02,  5.69308847e-02,  4.88394573e-02,\n",
      "         1.66010961e-01, -9.93605703e-02,  7.73657635e-02,\n",
      "        -2.63844077e-02, -1.45112172e-01,  1.64138645e-01,\n",
      "         2.87566781e-02,  8.64634514e-02, -2.59059332e-02,\n",
      "         1.15356833e-01,  1.28421366e-01,  1.43406838e-02,\n",
      "         5.24774455e-02,  4.91994321e-02]], dtype=float32),\n",
      " array([0., 0.], dtype=float32),\n",
      " array([[ 0.08700272],\n",
      "       [-0.19695964],\n",
      "       [ 0.02607708],\n",
      "       [-0.16302857],\n",
      "       [-0.09491075],\n",
      "       [-0.18331286],\n",
      "       [-0.04211992],\n",
      "       [ 0.21112543],\n",
      "       [ 0.04042622],\n",
      "       [ 0.1084682 ],\n",
      "       [-0.19203477],\n",
      "       [-0.18120614],\n",
      "       [ 0.1130468 ],\n",
      "       [ 0.12558249],\n",
      "       [-0.08421238],\n",
      "       [ 0.1127196 ],\n",
      "       [ 0.04300678],\n",
      "       [ 0.01859871],\n",
      "       [ 0.16642666],\n",
      "       [-0.00571924],\n",
      "       [-0.20998806],\n",
      "       [ 0.03792879],\n",
      "       [-0.07437269],\n",
      "       [-0.11283283],\n",
      "       [ 0.1840139 ],\n",
      "       [ 0.15710673],\n",
      "       [-0.13429442],\n",
      "       [ 0.06060857],\n",
      "       [-0.12151898],\n",
      "       [ 0.17463344],\n",
      "       [ 0.20406911],\n",
      "       [-0.10797773],\n",
      "       [-0.072414  ],\n",
      "       [-0.05235198],\n",
      "       [ 0.1467132 ],\n",
      "       [ 0.20314345],\n",
      "       [ 0.15569317],\n",
      "       [ 0.08470923],\n",
      "       [-0.05539051],\n",
      "       [ 0.08436993],\n",
      "       [ 0.17753649],\n",
      "       [-0.073599  ],\n",
      "       [-0.20866665],\n",
      "       [ 0.21358114],\n",
      "       [ 0.14902675],\n",
      "       [-0.04276095],\n",
      "       [ 0.17994875],\n",
      "       [-0.16620146],\n",
      "       [ 0.13524413],\n",
      "       [-0.18111174],\n",
      "       [-0.09278325],\n",
      "       [-0.054205  ],\n",
      "       [-0.20660625],\n",
      "       [ 0.11870316],\n",
      "       [ 0.09381491],\n",
      "       [-0.1500455 ],\n",
      "       [-0.1925763 ],\n",
      "       [-0.08956845],\n",
      "       [ 0.04063886],\n",
      "       [-0.17932154],\n",
      "       [-0.00845997],\n",
      "       [-0.02397406],\n",
      "       [ 0.08288491],\n",
      "       [ 0.20095441],\n",
      "       [ 0.07829717],\n",
      "       [ 0.10661966],\n",
      "       [ 0.09339261],\n",
      "       [-0.04193291],\n",
      "       [ 0.14652658],\n",
      "       [-0.07477613],\n",
      "       [-0.02685329],\n",
      "       [ 0.10305306],\n",
      "       [-0.03390172],\n",
      "       [-0.09637166],\n",
      "       [ 0.09531167],\n",
      "       [-0.20221885],\n",
      "       [ 0.20870075],\n",
      "       [-0.02063468],\n",
      "       [-0.02723734],\n",
      "       [-0.05637698],\n",
      "       [ 0.14236328],\n",
      "       [-0.08921839],\n",
      "       [-0.02423814],\n",
      "       [-0.05770816],\n",
      "       [-0.11904786],\n",
      "       [-0.20741116],\n",
      "       [-0.0474382 ],\n",
      "       [-0.14883325],\n",
      "       [ 0.0473856 ],\n",
      "       [-0.02749413],\n",
      "       [ 0.06204343],\n",
      "       [-0.1358397 ],\n",
      "       [ 0.08042514],\n",
      "       [-0.12131599],\n",
      "       [ 0.17026225],\n",
      "       [-0.08924164],\n",
      "       [ 0.14615515],\n",
      "       [-0.20736235],\n",
      "       [ 0.06706995],\n",
      "       [-0.1403502 ],\n",
      "       [ 0.04566312],\n",
      "       [-0.04902215],\n",
      "       [-0.21019492],\n",
      "       [-0.1337541 ],\n",
      "       [ 0.10474452],\n",
      "       [-0.1647733 ],\n",
      "       [ 0.1221284 ],\n",
      "       [ 0.02634478],\n",
      "       [-0.20796616],\n",
      "       [ 0.01069781],\n",
      "       [-0.09352861],\n",
      "       [-0.16509277],\n",
      "       [ 0.18948543],\n",
      "       [ 0.02834943],\n",
      "       [-0.06981149],\n",
      "       [ 0.03746945],\n",
      "       [ 0.0477353 ],\n",
      "       [ 0.06965733],\n",
      "       [-0.0685869 ],\n",
      "       [-0.13090114],\n",
      "       [-0.17635721],\n",
      "       [-0.1692783 ],\n",
      "       [-0.06262811],\n",
      "       [-0.02458502],\n",
      "       [-0.11013957],\n",
      "       [-0.06080808],\n",
      "       [ 0.20201236],\n",
      "       [-0.02596694]], dtype=float32),\n",
      " array([0.], dtype=float32)]\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer Context has arguments in `__init__` and therefore must override `get_config`.\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7412 - binary_accuracy: 0.2500\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6636 - binary_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6001 - binary_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5443 - binary_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4975 - binary_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4519 - binary_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4114 - binary_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3743 - binary_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3416 - binary_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3113 - binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer Context has arguments in `__init__` and therefore must override `get_config`.\n",
      "Epoch 11/20\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.4178 - binary_accuracy: 0.0000e+00\n",
      "Switching contexts to 1\n",
      "8/4 [============================================================] - 0s 4ms/step - loss: 0.9078 - binary_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7303 - binary_accuracy: 0.5000\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6054 - binary_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5134 - binary_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4397 - binary_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3854 - binary_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3349 - binary_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2947 - binary_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2636 - binary_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2332 - binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer Context has arguments in `__init__` and therefore must override `get_config`.\n",
      "Epoch 21/30\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.8290 - binary_accuracy: 0.0000e+00\n",
      "Switching contexts to 0\n",
      "8/4 [============================================================] - 0s 5ms/step - loss: 0.2758 - binary_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2422 - binary_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2137 - binary_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1898 - binary_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1711 - binary_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1543 - binary_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1404 - binary_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1279 - binary_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1172 - binary_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1083 - binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer Context has arguments in `__init__` and therefore must override `get_config`.\n",
      "Epoch 31/40\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 2.4808 - binary_accuracy: 0.0000e+00\n",
      "Switching contexts to 1\n",
      "8/4 [============================================================] - 0s 4ms/step - loss: 0.1630 - binary_accuracy: 1.0000\n",
      "Epoch 32/40\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1460 - binary_accuracy: 1.0000\n",
      "Epoch 33/40\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1298 - binary_accuracy: 1.0000\n",
      "Epoch 34/40\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1168 - binary_accuracy: 1.0000\n",
      "Epoch 35/40\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1063 - binary_accuracy: 1.0000\n",
      "Epoch 36/40\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0973 - binary_accuracy: 1.0000\n",
      "Epoch 37/40\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0895 - binary_accuracy: 1.0000\n",
      "Epoch 38/40\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0826 - binary_accuracy: 1.0000\n",
      "Epoch 39/40\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0767 - binary_accuracy: 1.0000\n",
      "Epoch 40/40\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0713 - binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer Context has arguments in `__init__` and therefore must override `get_config`.\n",
      "Epoch 41/50\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 2.9192 - binary_accuracy: 0.0000e+00\n",
      "Switching contexts to 0\n",
      "8/4 [============================================================] - 0s 4ms/step - loss: 0.0754 - binary_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0702 - binary_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0652 - binary_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0614 - binary_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0575 - binary_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0543 - binary_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0515 - binary_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0486 - binary_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0462 - binary_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0439 - binary_accuracy: 1.0000\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer Context has arguments in `__init__` and therefore must override `get_config`.\n",
      "Epoch 51/60\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 3.3363 - binary_accuracy: 0.0000e+00\n",
      "Switching contexts to 1\n",
      "8/4 [============================================================] - 0s 4ms/step - loss: 0.0540 - binary_accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0507 - binary_accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0480 - binary_accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0454 - binary_accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0432 - binary_accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0410 - binary_accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0391 - binary_accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0373 - binary_accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0358 - binary_accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0342 - binary_accuracy: 1.0000\n",
      "array([[0.04017282],\n",
      "       [0.9716959 ],\n",
      "       [0.96546537],\n",
      "       [0.0312354 ]], dtype=float32)\n",
      "array([[0.968927  ],\n",
      "       [0.02732682],\n",
      "       [0.03393403],\n",
      "       [0.9640705 ]], dtype=float32)\n",
      "4/4; Accuracy: 100.00%\n",
      "CPU times: user 3.22 s, sys: 281 ms, total: 3.5 s\n",
      "Wall time: 3.18 s\n"
     ]
    }
   ],
   "source": [
    "%time model = test_context(NTaskModel, {}, {\"metrics\": [tf.keras.metrics.BinaryAccuracy()]}, logic_gate_inputs, logic_gate_labels[:2], cycles=3, epochs=10, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extended Model\n",
    "\n",
    "The model below serves as a new base model for NTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import copy\n",
    "\n",
    "from tensorflow.python.keras.mixed_precision.experimental import loss_scale_optimizer as lso\n",
    "from tensorflow.python.data.experimental.ops import distribute_options\n",
    "from tensorflow.python.data.ops import dataset_ops\n",
    "\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import random_ops\n",
    "\n",
    "from tensorflow.python.eager import backprop\n",
    "from tensorflow.python.eager import context\n",
    "from tensorflow.python.profiler import traceme\n",
    "\n",
    "from tensorflow.python.distribute import distribution_strategy_context as ds_context\n",
    "from tensorflow.python.distribute import parameter_server_strategy\n",
    "from tensorflow.python.keras import backend\n",
    "from tensorflow.python.keras import callbacks as callbacks_module\n",
    "from tensorflow.python.keras.utils import version_utils\n",
    "from tensorflow.python.keras.engine import training_utils\n",
    "from tensorflow.python.keras.engine import data_adapter\n",
    "from tensorflow.python.keras.engine import training\n",
    "from tensorflow.python.util import nest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrowed from https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/engine/data_adapter.py\n",
    "try:\n",
    "    import pandas as pd  # pylint: disable=g-import-not-at-top\n",
    "except ImportError:\n",
    "    pd = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _minimize(strategy, tape, optimizer, loss, trainable_variables):\n",
    "    \"\"\"Minimizes loss for one step by updating `trainable_variables`.\n",
    "    This is roughly equivalent to\n",
    "    ```python\n",
    "    gradients = tape.gradient(loss, trainable_variables)\n",
    "    self.optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "    ```\n",
    "    However, this function also applies gradient clipping and loss scaling if the\n",
    "    optimizer is a LossScaleOptimizer.\n",
    "    Args:\n",
    "      strategy: `tf.distribute.Strategy`.\n",
    "      tape: A gradient tape. The loss must have been computed under this tape.\n",
    "      optimizer: The optimizer used to minimize the loss.\n",
    "      loss: The loss tensor.\n",
    "      trainable_variables: The variables that will be updated in order to minimize\n",
    "        the loss.\n",
    "    Return:\n",
    "      gradients\n",
    "    \"\"\"\n",
    "\n",
    "    with tape:\n",
    "        if isinstance(optimizer, lso.LossScaleOptimizer):\n",
    "            loss = optimizer.get_scaled_loss(loss)\n",
    "\n",
    "    gradients = tape.gradient(loss, trainable_variables)\n",
    "\n",
    "    # Whether to aggregate gradients outside of optimizer. This requires support\n",
    "    # of the optimizer and doesn't work with ParameterServerStrategy and\n",
    "    # CentralStroageStrategy.\n",
    "    aggregate_grads_outside_optimizer = (\n",
    "        optimizer._HAS_AGGREGATE_GRAD and  # pylint: disable=protected-access\n",
    "        not isinstance(strategy.extended,\n",
    "                       parameter_server_strategy.ParameterServerStrategyExtended))\n",
    "\n",
    "    if aggregate_grads_outside_optimizer:\n",
    "        # We aggregate gradients before unscaling them, in case a subclass of\n",
    "        # LossScaleOptimizer all-reduces in fp16. All-reducing in fp16 can only be\n",
    "        # done on scaled gradients, not unscaled gradients, for numeric stability.\n",
    "        gradients = optimizer._aggregate_gradients(zip(gradients,  # pylint: disable=protected-access\n",
    "                                                       trainable_variables))\n",
    "    if isinstance(optimizer, lso.LossScaleOptimizer):\n",
    "        gradients = optimizer.get_unscaled_gradients(gradients)\n",
    "    gradients = optimizer._clip_gradients(gradients)  # pylint: disable=protected-access\n",
    "    if trainable_variables:\n",
    "        if aggregate_grads_outside_optimizer:\n",
    "            optimizer.apply_gradients(\n",
    "                zip(gradients, trainable_variables),\n",
    "                experimental_aggregate_gradients=False)\n",
    "        else:\n",
    "            optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extended from https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/engine/data_adapter.py\n",
    "class WindowedDataHandler(data_adapter.DataHandler):\n",
    "    \"\"\"\n",
    "    Enumerating over this data handler yields windows of the dataset.\n",
    "    This is important for n-task because if a context switch occurs\n",
    "    during an epoch the data needs to be sent back through the network.\n",
    "    \"\"\"\n",
    "    def calc_window_size(self):\n",
    "        batch_size = self._adapter.batch_size()\n",
    "        num_samples = self._inferred_steps*batch_size\n",
    "        if self._adapter.has_partial_batch():\n",
    "            num_samples -= batch_size - self._adapter.partial_batch_size()\n",
    "        return np.ceil(num_samples/min(batch_size, num_samples))\n",
    "    \n",
    "    def enumerate_epochs(self):\n",
    "        data_iterator = iter(self._dataset.window(self.calc_window_size()))\n",
    "        for epoch in range(self._initial_epoch, self._epochs):\n",
    "            if self._insufficient_data:\n",
    "                break\n",
    "            if self._adapter.should_recreate_iterator():\n",
    "                data_iterator = iter(self._dataset.window(self.calc_window_size()))\n",
    "            yield epoch, data_iterator\n",
    "            self._adapter.on_epoch_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extended from https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/engine/training.py\n",
    "class NTaskModelBase(Model):\n",
    "    \"\"\"\n",
    "    This abstract model integrates the raw mechanisms and handlers into\n",
    "    Tensorflow Keras' model class. These mechanisms can be implemented by\n",
    "    inheriting from this class.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(NTaskModelBase, self).__init__(*args, **kwargs)\n",
    "        self.accumulate_gradients = False\n",
    "        self.accumulated_gradients = None\n",
    "        \n",
    "        \n",
    "    def compile(self, *args, accumulate_gradients=False, **kwargs):\n",
    "        super(NTaskModelBase, self).compile(*args, **kwargs)\n",
    "        \n",
    "        # TODO\n",
    "        if accumulate_gradients:\n",
    "            self.accumulate_gradients = True\n",
    "        \n",
    "    \n",
    "    def train_step(self, data):\n",
    "        data = data_adapter.expand_1d(data)\n",
    "        x, y, sample_weight = data_adapter.unpack_x_y_sample_weight(data)\n",
    "\n",
    "        with backprop.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)\n",
    "            loss = self.compiled_loss(y, y_pred, sample_weight, regularization_losses=self.losses)\n",
    "            \n",
    "        gradients = _minimize(self.distribute_strategy, tape, self.optimizer, loss,\n",
    "              self.trainable_variables)\n",
    "        \n",
    "        # Add context loss to layers\n",
    "        self.add_context_loss(gradients)\n",
    "\n",
    "        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    \n",
    "    @training.enable_multi_worker\n",
    "    def fit(self,\n",
    "            x=None,\n",
    "            y=None,\n",
    "            batch_size=None,\n",
    "            epochs=1,\n",
    "            verbose=1,\n",
    "            dynamic_switch=True,\n",
    "            callbacks=None,\n",
    "            validation_split=0.,\n",
    "            validation_data=None,\n",
    "            shuffle=True,\n",
    "            class_weight=None,\n",
    "            sample_weight=None,\n",
    "            initial_epoch=0,\n",
    "            steps_per_epoch=None,\n",
    "            validation_steps=None,\n",
    "            validation_batch_size=None,\n",
    "            validation_freq=1,\n",
    "            max_queue_size=10,\n",
    "            workers=1,\n",
    "            use_multiprocessing=False):\n",
    "\n",
    "        training._keras_api_gauge.get_cell('fit').set(True)\n",
    "        # Legacy graph support is contained in `training_v1.Model`.\n",
    "        version_utils.disallow_legacy_graph('Model', 'fit')\n",
    "        self._assert_compile_was_called()\n",
    "        self._check_call_args('fit')\n",
    "\n",
    "        if validation_split:\n",
    "            # Create the validation data using the training data. Only supported for\n",
    "            # `Tensor` and `NumPy` input.\n",
    "            (x, y, sample_weight), validation_data = (\n",
    "            data_adapter.train_validation_split((x, y, sample_weight),\n",
    "                                                validation_split=validation_split,\n",
    "                                                shuffle=False))\n",
    "\n",
    "        with self.distribute_strategy.scope(), training_utils.RespectCompiledTrainableState(self):\n",
    "            # Creates a `tf.data.Dataset` and handles batch and epoch iteration.\n",
    "            data_handler = WindowedDataHandler(\n",
    "                x=x,\n",
    "                y=y,\n",
    "                sample_weight=sample_weight,\n",
    "                batch_size=batch_size,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                initial_epoch=initial_epoch,\n",
    "                epochs=epochs,\n",
    "                shuffle=shuffle,\n",
    "                class_weight=class_weight,\n",
    "                max_queue_size=max_queue_size,\n",
    "                workers=workers,\n",
    "                use_multiprocessing=use_multiprocessing,\n",
    "                model=self)\n",
    "\n",
    "            # Container that configures and calls `tf.keras.Callback`s.\n",
    "            if not isinstance(callbacks, callbacks_module.CallbackList):\n",
    "                callbacks = callbacks_module.CallbackList(\n",
    "                    callbacks,\n",
    "                    add_history=True,\n",
    "                    add_progbar=bool(verbose & Verbosity.Progress),\n",
    "                    model=self,\n",
    "                    verbose=verbose,\n",
    "                    epochs=epochs,\n",
    "                    steps=data_handler.inferred_steps)\n",
    "\n",
    "            self.stop_training = False\n",
    "            train_function = self.make_train_function()\n",
    "            callbacks.on_train_begin()\n",
    "            # Handle fault-tolerance for multi-worker.\n",
    "            # TODO(omalleyt): Fix the ordering issues that mean this has to\n",
    "            # happen after `callbacks.on_train_begin`.\n",
    "            data_handler._initial_epoch = (self._maybe_load_initial_epoch_from_ckpt(initial_epoch))\n",
    "            for epoch, window_iterator in data_handler.enumerate_epochs():\n",
    "                self.reset_metrics()\n",
    "                callbacks.on_epoch_begin(epoch)\n",
    "                dataset = tf.data.Dataset.zip(next(window_iterator))\n",
    "                switched = True\n",
    "                weights = backend.batch_get_value(self.trainable_variables)\n",
    "                while switched:\n",
    "                    self.initialize_epoch(epoch)\n",
    "                    iterator = iter(dataset)\n",
    "                    with data_handler.catch_stop_iteration():\n",
    "                        for step in data_handler.steps():\n",
    "                            with traceme.TraceMe( 'TraceContext', graph_type='train', epoch_num=epoch, step_num=step, batch_size=batch_size):\n",
    "                                callbacks.on_train_batch_begin(step)\n",
    "                                tmp_logs = train_function(iterator)\n",
    "                                # Catch OutOfRangeError for Datasets of unknown size.\n",
    "                                # This blocks until the batch has finished executing.\n",
    "                                # TODO(b/150292341): Allow multiple async steps here.\n",
    "                                if not data_handler.inferred_steps:\n",
    "                                    context.async_wait()\n",
    "                                logs = tmp_logs  # No error, now safe to assign to logs.\n",
    "                                callbacks.on_train_batch_end(step, logs)\n",
    "                        switched = not self.update_and_switch(dynamic_switch, verbose)\n",
    "                        # If a switch occurred, we need to restore the weights\n",
    "                        if switched:\n",
    "                            backend.batch_set_value(zip(self.trainable_variables, weights))\n",
    "                            self.reset_metrics()\n",
    "                    \n",
    "                epoch_logs = copy.copy(logs)\n",
    "                \n",
    "                if self.accumulate_gradients:\n",
    "                    self.optimizer.apply_gradients(zip(self.accumulated_gradients, self.trainable_variables))\n",
    "\n",
    "                # Run validation.\n",
    "                if validation_data and self._should_eval(epoch, validation_freq):\n",
    "                    val_x, val_y, val_sample_weight = (\n",
    "                        data_adapter.unpack_x_y_sample_weight(validation_data))\n",
    "                    val_logs = self.evaluate(\n",
    "                        x=val_x,\n",
    "                        y=val_y,\n",
    "                        sample_weight=val_sample_weight,\n",
    "                        batch_size=validation_batch_size or batch_size,\n",
    "                        steps=validation_steps,\n",
    "                        callbacks=callbacks,\n",
    "                        max_queue_size=max_queue_size,\n",
    "                        workers=workers,\n",
    "                        use_multiprocessing=use_multiprocessing,\n",
    "                        return_dict=True)\n",
    "                    val_logs = {'val_' + name: val for name, val in val_logs.items()}\n",
    "                    epoch_logs.update(val_logs)\n",
    "\n",
    "                callbacks.on_epoch_end(epoch, epoch_logs)\n",
    "                if self.stop_training:\n",
    "                    break\n",
    "\n",
    "            callbacks.on_train_end()\n",
    "            return self.history\n",
    "        \n",
    "    def add_context_loss(self, gradients):\n",
    "        \"\"\"Calculate and add context loss to context layers\"\"\"\n",
    "        return\n",
    "        raise NotImplemented(\"`add_context_loss` not implemented\")\n",
    "        \n",
    "        \n",
    "    def initialize_epoch(self, epoch):\n",
    "        \"\"\"Reset context loss in context layers\"\"\"\n",
    "        return\n",
    "        raise NotImplemented(\"`initialize_epoch` not implemneted\")\n",
    "        \n",
    "        \n",
    "    def update_and_switch(self, dynamic_switch=True, verbose=0):\n",
    "        \"\"\"\n",
    "        Update the context layers\n",
    "        \n",
    "        Args:\n",
    "            dynamic_switch [bool]: Enable/disable dynamic switching mechanisms\n",
    "        Return:\n",
    "            [bool]: Indicate if no switches occurred\n",
    "        \"\"\"\n",
    "        return True\n",
    "        raise NotImplemented(\"`update_and_switch` not implemented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NTaskModel(NTaskModelBase):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(NTaskModel, self).__init__(*args, **kwargs)\n",
    "        self.ctx_layers = [i for i, layer in enumerate(self.layers) if isinstance(layer, Context)]\n",
    "        \n",
    "        # We need to map the context layer to their gradient indices\n",
    "        self.ctx_gradient_map = {}\n",
    "        index = 0\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if isinstance(layer, Context):\n",
    "                self.ctx_gradient_map[i] = index + 1 # The bias gradient\n",
    "            index += len(layer.trainable_variables)\n",
    "    \n",
    "    \n",
    "    def _calc_context_loss(self, ctx_layer_idx, gradients):\n",
    "        \"\"\"\n",
    "        IMPORTANT: \n",
    "        1) Assumes no use of activation function on Ntask layer\n",
    "        2) Assumes that the layer following the Ntask layer:\n",
    "            a) Is a Dense layer\n",
    "            b) Is using bias\n",
    "               — ex: Dense(20, ... , use_bias=True) \n",
    "               — note Keras Dense layer uses bias by default if no value is given for use_bias param\n",
    "        3) Assumes index of the next layer's gradient is known within the gradients list returned from gradient tape in a tape.gradient call\n",
    "        4) If the above points aren't met, things will break and it may be hard to locate the bugs\n",
    "        \"\"\"\n",
    "        # From the delta rule in neural network math        \n",
    "        index = self.ctx_gradient_map[ctx_layer_idx]\n",
    "        delta_at_next_layer = gradients[index]\n",
    "        transpose_of_weights_at_next_layer = tf.transpose(self.layers[ctx_layer_idx + 1].weights[0])\n",
    "        \n",
    "        # Calculate delta at n-task layer\n",
    "        context_delta = tf.tensordot(delta_at_next_layer, transpose_of_weights_at_next_layer, 1)\n",
    "        return context_delta\n",
    "    \n",
    "    \n",
    "    def initialize_epoch(self, epoch):\n",
    "        # Clear context loss (probably going to use a new mechanism here)\n",
    "#         for i in self.ctx_layers:\n",
    "#             self.layers[i].clear_context_loss()\n",
    "        pass\n",
    "            \n",
    "    \n",
    "    def add_context_loss(self, gradients):\n",
    "        for i in self.ctx_layers:\n",
    "            self.layers[i].add_context_loss(self._calc_context_loss(i, gradients))\n",
    "    \n",
    "    \n",
    "    def update_and_switch(self, dynamic_switch, verbose):\n",
    "        updated = True\n",
    "        for i in reversed(self.ctx_layers):\n",
    "            layer = self.layers[i]\n",
    "            updated &= layer.update_and_switch(dynamic_switch=dynamic_switch, verbose=verbose)\n",
    "        return updated\n",
    "    \n",
    "\n",
    "    def set_contexts(self, contexts):\n",
    "        for i, layer in enumerate(self.ctx_layers):\n",
    "            self.layers[layer].hot_context = contexts[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtrLogger(tf.keras.callbacks.BaseLogger):\n",
    "    \n",
    "    def __init__(self, logdir, *args, **kwargs):\n",
    "        super(AtrLogger, self).__init__(*args, **kwargs)\n",
    "        self.logdir = logdir\n",
    "        self.writers = {}\n",
    "        \n",
    "    def set_model(self, model):\n",
    "        super(AtrLogger, self).set_model(model)\n",
    "        self.writers = {self.model.layers[i]: [] for i in self.model.ctx_layers}\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\"Create the correct number of writers for the context if necessary\"\"\"\n",
    "        for layer, writers in self.writers.items():\n",
    "            for i in range(len(writers), layer.num_contexts):\n",
    "                writers.append(tf.summary.create_file_writer(os.path.join(self.logdir, f\"context_atr_{i}\"))) # TODO Fix this name here...\n",
    "            plot_tag = f\"context_atr_trace\"                                                                  # TODO Fix this name here too...\n",
    "            for i, writer in enumerate(writers):\n",
    "                with writer.as_default():\n",
    "                    value = layer.atr_model.values[i]\n",
    "                    if layer.atr_model.values_initialized[i]:\n",
    "                        tf.summary.scalar(plot_tag, data=value, step=epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          x_train,\n",
    "          y_train_tasks,\n",
    "          cycles=1,\n",
    "          epochs=1,\n",
    "          task_shuffle=True,\n",
    "          initial_task_shuffle=False,\n",
    "          explicit_contexts=False,\n",
    "          assert_contexts=False,\n",
    "          **kwargs):\n",
    "    \"\"\"\n",
    "    Train an NTask model on a dataset containing samples from multiple tasks.\n",
    "    \n",
    "    Args:\n",
    "      model            : The NTask model instance\n",
    "      x_train          : The input data\n",
    "      y_train_tasks    : A list of tuples containing the y_train value and context IDs.\n",
    "                         e.g. (y_train, 0, 2) # (y_train, context_layer_0 = 0, context_layer_1 = 2)\n",
    "      cycles           : The number of iterations over the entire y_train_tasks\n",
    "      epochs           : The number of epochs to perform on each y_train element within y_train_tasks\n",
    "      task_shuffle     : Shuffle the y_train_tasks on each cycle (does not shuffle data within the task)\n",
    "      initial_shuffle  :Shuffle the y_train_tasks on the first epoch. If set to false, context order within\n",
    "                         the context layers is guaranteed to remain in the same order as provided\n",
    "      explicit_contexts: If set to True, contexts will be set explicitly and dynamic switching will be disabled\n",
    "      **kwargs         : All other keyword arguments are passed to `model.fit`\n",
    "    \"\"\"\n",
    "    \n",
    "    indices = np.arange(len(y_train_tasks))\n",
    "    \n",
    "    if initial_task_shuffle and task_shuffle:\n",
    "        np.random.shuffle(indices)\n",
    "    \n",
    "    context_map = [y[1:] for y in y_train_tasks]\n",
    "    \n",
    "    for cycle in range(cycles):\n",
    "        for i, (y_train, *contexts) in enumerate(y_train_tasks):\n",
    "            \n",
    "            # Set contexts explicitly if necessary\n",
    "            if explicit_contexts:\n",
    "                model.set_contexts(contexts)\n",
    "                \n",
    "            model.fit(x_train, y_train, epochs=epochs, **kwargs)\n",
    "                \n",
    "        if task_shuffle:\n",
    "            np.random.shuffle(indices)\n",
    "            \n",
    "    return context_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(ModelClass, init_args, compile_args, x_train, y_train, seed=5, **kwargs):\n",
    "    # Set the random seed for all used libraries\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "    # Create the model\n",
    "    inp = Input(x_train[0].shape)\n",
    "    x = Dense(128, activation=\"relu\")(inp)\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = ModelClass(inputs=inp, outputs=x, **init_args)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        optimizer=tf.keras.optimizers.SGD(1e-4),\n",
    "        **compile_args\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(x_train, y_train, **kwargs)\n",
    "    \n",
    "    # Calculate and display the accuracy\n",
    "    result = (np.round(model(x_train)).astype(int).flatten() == y_train.flatten()).sum()\n",
    "    print(f\"{result}/{len(y_train)}; Accuracy: {100*result/len(y_train):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_context(ModelClass, init_args, compile_args, x_train, y_train_list, cycles=1, seed=5, epochs=1, **kwargs):\n",
    "    # Set the random seed for all used libraries\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "    # Create the model\n",
    "    inp = Input(x_train[0].shape)\n",
    "    x = Dense(128, activation=\"relu\", use_bias=True)(inp)\n",
    "    x = Context(2, AtrMovingAverage(max_contexts=2, switch_threshold=-0.02))(x)\n",
    "#     x = Context()(x)\n",
    "    x = Dense(1, activation=\"sigmoid\", use_bias=True)(x)\n",
    "    model = ModelClass(inputs=inp, outputs=x, **init_args)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        optimizer=tf.keras.optimizers.SGD(1e-1),\n",
    "        **compile_args\n",
    "    )\n",
    "    \n",
    "    logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1),\n",
    "        AtrLogger(logdir)\n",
    "    ]\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    tf.print(model.get_weights())\n",
    "    \n",
    "    # Train the model\n",
    "    for cycle in range(cycles):\n",
    "        for context, y_train in enumerate(y_train_list):\n",
    "            initial_epoch = cycle*len(y_train_list)*epochs + context*epochs\n",
    "#             model.set_contexts([context])\n",
    "            model.fit(x_train, y_train, callbacks=callbacks, initial_epoch=initial_epoch, epochs=initial_epoch + epochs, **kwargs)\n",
    "    \n",
    "    for context in range(len(y_train_list)):\n",
    "        model.set_contexts([context])\n",
    "        tf.print(model.predict(x_train))\n",
    "    \n",
    "    # Calculate and display the accuracy\n",
    "    result = (np.round(model(x_train)).astype(int).flatten() == y_train.flatten()).sum()\n",
    "    print(f\"{result}/{len(y_train)}; Accuracy: {100*result/len(y_train):.2f}%\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_context_dynamic(ModelClass, init_args, compile_args, x_train, y_train_list, cycles=1, seed=5, epochs=1, **kwargs):\n",
    "    # Set the random seed for all used libraries\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "    # Create the model\n",
    "    inp = Input(x_train[0].shape)\n",
    "    x = Dense(128, activation=\"relu\", use_bias=True)(inp)\n",
    "    x = Context(1, AtrMovingAverage(max_contexts=len(y_train_list)+1, switch_threshold=-0.02, add_threshold=-0.04))(x)\n",
    "    x = Dense(1, activation=\"sigmoid\", use_bias=True)(x)\n",
    "    model = ModelClass(inputs=inp, outputs=x, **init_args)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        optimizer=tf.keras.optimizers.SGD(1e-1),\n",
    "        **compile_args\n",
    "    )\n",
    "    \n",
    "    logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1),\n",
    "        AtrLogger(logdir)\n",
    "    ]\n",
    "    \n",
    "    # Train the model\n",
    "    for cycle in range(cycles):\n",
    "        for context, y_train in enumerate(y_train_list):\n",
    "            initial_epoch = cycle*len(y_train_list)*epochs + context*epochs\n",
    "#             model.set_contexts([context])\n",
    "            model.fit(x_train, y_train, callbacks=callbacks, initial_epoch=initial_epoch, epochs=initial_epoch + epochs, **kwargs)\n",
    "    \n",
    "    for context in range(len(y_train_list)):\n",
    "        model.set_contexts([context])\n",
    "        tf.print(model.predict(x_train))\n",
    "    \n",
    "    # Calculate and display the accuracy\n",
    "    result = (np.round(model(x_train)).astype(int).flatten() == y_train.flatten()).sum()\n",
    "    print(f\"{result}/{len(y_train)}; Accuracy: {100*result/len(y_train):.2f}%\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-721-e2fe961fd06c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Training images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtraining_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../datasets/mnist/train-images.idx3-ubyte\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtraining_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Development/Jupyter/n-task/experiment/utils.py\u001b[0m in \u001b[0;36midx_load\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\">{data_type}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m                 \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training images\n",
    "training_images = idx_load(\"../datasets/mnist/train-images.idx3-ubyte\")\n",
    "training_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training labels\n",
    "training_labels = idx_load(\"../datasets/mnist/train-labels.idx1-ubyte\")\n",
    "training_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the datasets\n",
    "training_images = training_images.reshape(len(training_images), 28*28) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "logic_gate_labels = np.array([\n",
    "    [[0], [1], [1], [0]], # XOR\n",
    "    [[1], [0], [0], [1]], # XNOR\n",
    "    [[0], [0], [0], [1]], # AND\n",
    "    [[0], [1], [1], [1]], # OR\n",
    "    [[1], [0], [0], [0]], # NOR\n",
    "    [[1], [1], [1], [0]], # NAND\n",
    "    [[1], [0], [1], [0]], # Custom 1\n",
    "    [[0], [1], [0], [1]]  # Custom 2\n",
    "])\n",
    "\n",
    "logic_gate_inputs = np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST number is even\n",
    "x_train = training_images\n",
    "y_train = np.array([int(i % 2 == 0) for i in training_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1 4]\n",
      "[0 1 1 0 0 1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Verify on the first 10 the dataset seems correct...\n",
    "print(training_labels[:10])\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.6916 - accuracy: 0.5445\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.6590 - accuracy: 0.6339\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.6337 - accuracy: 0.6905\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.6120 - accuracy: 0.7269\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.5925 - accuracy: 0.7527\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.5748 - accuracy: 0.7689\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.5585 - accuracy: 0.7812\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.5436 - accuracy: 0.7921\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.7985\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.5172 - accuracy: 0.8041\n",
      "48394/60000; Accuracy: 80.66%\n",
      "CPU times: user 38.6 s, sys: 16.8 s, total: 55.4 s\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%time test(Model, {}, {\"metrics\": [\"accuracy\"]}, x_train, y_train, epochs=10, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.6916 - accuracy: 0.5445\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.6590 - accuracy: 0.6339\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.6337 - accuracy: 0.6905\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.6120 - accuracy: 0.7269\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.5925 - accuracy: 0.7527\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.5748 - accuracy: 0.7689\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.5585 - accuracy: 0.7812\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.5436 - accuracy: 0.7921\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.5299 - accuracy: 0.7985\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.5172 - accuracy: 0.8041\n",
      "48394/60000; Accuracy: 80.66%\n",
      "CPU times: user 36.9 s, sys: 16.4 s, total: 53.3 s\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%time test(NTaskModel, {}, {\"metrics\": [\"accuracy\"]}, x_train, y_train, epochs=10, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/4; Accuracy: 50.00%\n",
      "CPU times: user 3.06 s, sys: 406 ms, total: 3.47 s\n",
      "Wall time: 2.65 s\n"
     ]
    }
   ],
   "source": [
    "%time test(NTaskModel, {}, {}, logic_gate_inputs, logic_gate_labels[0], epochs=500, batch_size=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DictWrapper({})\n",
      "1/1 [==============================] - 0s 870us/step - loss: 0.7324\n",
      "2/4; Accuracy: 50.00%\n",
      "CPU times: user 250 ms, sys: 15.6 ms, total: 266 ms\n",
      "Wall time: 243 ms\n"
     ]
    }
   ],
   "source": [
    "%time test(NTaskModel, {}, {}, logic_gate_inputs, logic_gate_labels[0], epochs=1, batch_size=4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_contexts([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 893us/step - loss: 6.0130e-04 - binary_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0006013047532178462, 1.0]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(logic_gate_inputs, logic_gate_labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([\n",
    "    [[0], [1], [1], [0]], # XOR\n",
    "    [[1], [0], [0], [1]], # XNOR\n",
    "    [[0], [0], [0], [1]], # AND\n",
    "    [[0], [1], [1], [1]], # OR\n",
    "    [[1], [0], [0], [0]], # NOR\n",
    "    [[1], [1], [1], [0]], # NAND\n",
    "    [[1], [0], [1], [0]], # Custom 1\n",
    "    [[0], [1], [0], [1]]  # Custom 2\n",
    "])\n",
    "\n",
    "x_train = np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logic_gate_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill 4469"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4164d8399f767c45\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4164d8399f767c45\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
