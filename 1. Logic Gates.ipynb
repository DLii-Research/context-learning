{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logic Gate Task\n",
    "\n",
    "This task utilizes a simple neural network containing single n-task context layer to learn eight different logic gates.\n",
    "\n",
    "**Note:** This experiment uses a variation of the traditional n-task model to incorporate learning between batches instead of applying gradients at the end of batches. The idea is that learning will be much faster and more stable while retaining the ability to switch on bad contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Import n-task\n",
    "from ntask.atrs import AtrMovingAverage\n",
    "from ntask.callbacks import AtrLogger\n",
    "from ntask.flags import Verbosity\n",
    "from ntask.layers import Context\n",
    "from ntask.models import NTaskModel\n",
    "from ntask.training import train, evaluate\n",
    "from ntask.utils import set_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation Setup\n",
    "\n",
    "The following cells here build everything up for the experiments to execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Creation\n",
    "\n",
    "The following cell creates the base dataset with all of the gates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the gates explicitly\n",
    "gates = {\n",
    "    \"xor\":      [0, 1, 1, 0],\n",
    "    \"xnor\":     [1, 0, 0, 1],\n",
    "    \"and\":      [0, 0, 0, 1],\n",
    "    \"or\":       [0, 1, 1, 1],\n",
    "    \"nor\":      [1, 0, 0, 0],\n",
    "    \"nand\":     [1, 1, 1, 0],\n",
    "    \"custom_1\": [1, 0, 1, 0],\n",
    "    \"custom_2\": [0, 1, 0, 1]\n",
    "}\n",
    "\n",
    "# Build the labels used for `y_train` to work with the `train` convenience function\n",
    "y_labels = [np.array([[i] for i in gate]) for gate in gates.values()]\n",
    "\n",
    "# The inputs for each of the gates\n",
    "x_train = np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture and Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function creates a new instance of the model for each experiment. The hyperparameters are provided as arguments. The model summary is also displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(tag, optimizer, num_contexts, max_contexts=0, switch_threshold=0.0, add_threshold=0.0, summary=True):\n",
    "    # Model architecture\n",
    "    inp = Input((2,))\n",
    "    x = Dense(hrr_size, activation=\"relu\")(inp)\n",
    "    x = Context(\n",
    "        num_contexts,\n",
    "        AtrMovingAverage(max_contexts=max_contexts, switch_threshold=switch_threshold, add_threshold=add_threshold),\n",
    "        name=\"Gate_Context\"\n",
    "    )(x)\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = NTaskModel(inputs=inp, outputs=x)\n",
    "    \n",
    "    # Compile the model together with binary_crossentropy loss\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        optimizer=optimizer,\n",
    "        metrics=[\n",
    "            tf.keras.metrics.BinaryAccuracy()\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Set up logging so we can track and analyze how the model is performing in detail\n",
    "    logdir = os.path.join(\"logs\", tag, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1),\n",
    "        AtrLogger(logdir)\n",
    "    ]\n",
    "    \n",
    "    # Display the model summary\n",
    "    if summary:\n",
    "        model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static n-task: (XOR, XNOR)\n",
    "\n",
    "The following experiments demonstrates the model successfully learning two separate logic gates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG = \"static-2-gate\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_labels[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"n_task_model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               384       \n",
      "_________________________________________________________________\n",
      "Gate_Context (Context)       (None, 128)               260       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 773\n",
      "Trainable params: 513\n",
      "Non-trainable params: 260\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.SGD(1e-1)\n",
    "\n",
    "# Hyperparameters\n",
    "hrr_size         = 128\n",
    "num_contexts     = len(y_train)\n",
    "switch_threshold = -0.02\n",
    "\n",
    "# Create the model\n",
    "model = create_model(TAG, optimizer, num_contexts=len(y_train), switch_threshold=switch_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Gate_Context] Switching context to 1\n",
      "\n",
      "[Gate_Context] Switching context to 0\n",
      "\n",
      "[Gate_Context] Switching context to 1\n",
      "\n",
      "[Gate_Context] Switching context to 0\n",
      "CPU times: user 906 ms, sys: 297 ms, total: 1.2 s\n",
      "Wall time: 838 ms\n"
     ]
    }
   ],
   "source": [
    "cycles     = 3\n",
    "epochs     = 10\n",
    "batch_size = 1\n",
    "\n",
    "shuffle              = True  # Shuffle the active context dataset during training\n",
    "task_shuffle         = True  # Shuffle the contexts during training after first epoch\n",
    "initial_task_shuffle = True  # Shuffle the contexts before training\n",
    "\n",
    "verbose = Verbosity.Contexts\n",
    "\n",
    "# Benchmark the model\n",
    "%time task_map, context_map = train(model, x_train, y_train, cycles, epochs, task_shuffle, initial_task_shuffle, batch_size=batch_size, shuffle=shuffle, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0.04025948],\n",
      "       [0.96960604],\n",
      "       [0.96226275],\n",
      "       [0.03171104]], dtype=float32)\n",
      "array([[0.97145987],\n",
      "       [0.02444988],\n",
      "       [0.03115296],\n",
      "       [0.9637778 ]], dtype=float32)\n",
      "CPU times: user 172 ms, sys: 31.2 ms, total: 203 ms\n",
      "Wall time: 184 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'loss': 0.03566252812743187, 'binary_accuracy': 1.0},\n",
       " {'loss': 0.030563028529286385, 'binary_accuracy': 1.0}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1\n",
    "display_predictions = True\n",
    "verbose = 0\n",
    "\n",
    "%time evaluate(model, x_train, y_train, task_map, context_map, display_predictions, batch_size=batch_size, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic n-task: (XOR, XNOR)\n",
    "\n",
    "The following experiments demonstrates the model successfully learning two separate logic gates dynamically adding contexts to the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG = \"dynamic-2-gate\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_labels[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"n_task_model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               384       \n",
      "_________________________________________________________________\n",
      "Gate_Context (Context)       (None, 128)               260       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 773\n",
      "Trainable params: 513\n",
      "Non-trainable params: 260\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.SGD(1e-1)\n",
    "\n",
    "# Hyperparameters\n",
    "hrr_size         = 128\n",
    "num_contexts     = 1\n",
    "max_contexts     = len(y_train)\n",
    "switch_threshold = -0.02\n",
    "add_threshold    = -0.04\n",
    "\n",
    "# Create the model\n",
    "model = create_model(TAG, optimizer, num_contexts=num_contexts, max_contexts=max_contexts, switch_threshold=switch_threshold, add_threshold=add_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Gate_Context] Adding context 1\n",
      "\n",
      "[Gate_Context] Switching context to 0\n",
      "\n",
      "[Gate_Context] Switching context to 1\n",
      "\n",
      "[Gate_Context] Switching context to 0\n",
      "CPU times: user 969 ms, sys: 78.1 ms, total: 1.05 s\n",
      "Wall time: 859 ms\n"
     ]
    }
   ],
   "source": [
    "cycles     = 3\n",
    "epochs     = 10\n",
    "batch_size = 1\n",
    "\n",
    "shuffle              = True  # Shuffle the active context dataset during training\n",
    "task_shuffle         = True  # Shuffle the contexts during training after first epoch\n",
    "initial_task_shuffle = True  # Shuffle the contexts before training\n",
    "\n",
    "verbose = Verbosity.Contexts\n",
    "\n",
    "# Benchmark the model\n",
    "%time task_map, context_map = train(model, x_train, y_train, cycles, epochs, task_shuffle, initial_task_shuffle, batch_size=batch_size, shuffle=shuffle, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0.04025948],\n",
      "       [0.96960604],\n",
      "       [0.96226275],\n",
      "       [0.03171104]], dtype=float32)\n",
      "array([[0.97145987],\n",
      "       [0.02444988],\n",
      "       [0.03115296],\n",
      "       [0.9637778 ]], dtype=float32)\n",
      "CPU times: user 297 ms, sys: 46.9 ms, total: 344 ms\n",
      "Wall time: 289 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'loss': 0.03566252812743187, 'binary_accuracy': 1.0},\n",
       " {'loss': 0.030563028529286385, 'binary_accuracy': 1.0}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1\n",
    "display_predictions = True\n",
    "verbose = 0\n",
    "\n",
    "%time evaluate(model, x_train, y_train, task_map, context_map, display_predictions, batch_size=batch_size, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static n-task: All Gates\n",
    "\n",
    "The following experiments demonstrates the model successfully learning two separate logic gates dynamically adding contexts to the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG = \"static-all-gates\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_labels[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"n_task_model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               384       \n",
      "_________________________________________________________________\n",
      "Gate_Context (Context)       (None, 128)               1034      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,547\n",
      "Trainable params: 513\n",
      "Non-trainable params: 1,034\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.SGD(1e-1)\n",
    "\n",
    "# Hyperparameters\n",
    "hrr_size         = 128\n",
    "num_contexts     = len(y_train)\n",
    "switch_threshold = -0.02\n",
    "\n",
    "# Create the model\n",
    "model = create_model(TAG, optimizer, num_contexts=num_contexts, switch_threshold=switch_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.19 s, sys: 391 ms, total: 3.58 s\n",
      "Wall time: 2.98 s\n"
     ]
    }
   ],
   "source": [
    "cycles     = 3\n",
    "epochs     = 10\n",
    "batch_size = 1\n",
    "\n",
    "shuffle              = True  # Shuffle the active context dataset during training\n",
    "task_shuffle         = True  # Shuffle the contexts during training after first epoch\n",
    "initial_task_shuffle = True  # Shuffle the contexts before training\n",
    "\n",
    "verbose = 0 # Verbosity.Contexts\n",
    "\n",
    "# Benchmark the model\n",
    "%time task_map, context_map = train(model, x_train, y_train, cycles, epochs, task_shuffle, initial_task_shuffle, batch_size=batch_size, shuffle=shuffle, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0.00593275],\n",
      "       [0.98893386],\n",
      "       [0.9847105 ],\n",
      "       [0.02813032]], dtype=float32)\n",
      "array([[0.98548245],\n",
      "       [0.01487198],\n",
      "       [0.01345024],\n",
      "       [0.9954912 ]], dtype=float32)\n",
      "array([[0.00240618],\n",
      "       [0.00584942],\n",
      "       [0.00997534],\n",
      "       [0.9820519 ]], dtype=float32)\n",
      "array([[0.01358461],\n",
      "       [0.98393106],\n",
      "       [0.9841983 ],\n",
      "       [0.9930084 ]], dtype=float32)\n",
      "array([[0.98782384],\n",
      "       [0.01603228],\n",
      "       [0.01002574],\n",
      "       [0.0028097 ]], dtype=float32)\n",
      "array([[0.9954127 ],\n",
      "       [0.9846736 ],\n",
      "       [0.9950181 ],\n",
      "       [0.00408122]], dtype=float32)\n",
      "array([[0.9973501 ],\n",
      "       [0.00511506],\n",
      "       [0.9934953 ],\n",
      "       [0.00752574]], dtype=float32)\n",
      "array([[0.00310922],\n",
      "       [0.99892855],\n",
      "       [0.01164132],\n",
      "       [0.9962133 ]], dtype=float32)\n",
      "CPU times: user 500 ms, sys: 31.2 ms, total: 531 ms\n",
      "Wall time: 476 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'loss': 0.015254860743880272, 'binary_accuracy': 1.0},\n",
       " {'loss': 0.011917021125555038, 'binary_accuracy': 1.0},\n",
       " {'loss': 0.009103082120418549, 'binary_accuracy': 1.0},\n",
       " {'loss': 0.01320531964302063, 'binary_accuracy': 1.0},\n",
       " {'loss': 0.01032579317688942, 'binary_accuracy': 1.0},\n",
       " {'loss': 0.00728169921785593, 'binary_accuracy': 1.0},\n",
       " {'loss': 0.005465449765324593, 'binary_accuracy': 1.0},\n",
       " {'loss': 0.004922402091324329, 'binary_accuracy': 1.0}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1\n",
    "display_predictions = True\n",
    "verbose = 0\n",
    "\n",
    "%time evaluate(model, x_train, y_train, task_map, context_map, display_predictions, batch_size=batch_size, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic n-task: All Gates\n",
    "\n",
    "The following experiments demonstrates the model successfully learning two separate logic gates dynamically adding contexts to the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG = \"dynamic-all-gates\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_labels[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"n_task_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               384       \n",
      "_________________________________________________________________\n",
      "Gate_Context (Context)       (None, 128)               1034      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,547\n",
      "Trainable params: 513\n",
      "Non-trainable params: 1,034\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.SGD(1e-1)\n",
    "\n",
    "# Hyperparameters\n",
    "hrr_size         = 128\n",
    "num_contexts     = 1\n",
    "max_contexts     = len(y_train)\n",
    "switch_threshold = -0.02\n",
    "add_threshold    = -0.08\n",
    "\n",
    "# Create the model\n",
    "model = create_model(TAG, optimizer, num_contexts=num_contexts, max_contexts=max_contexts, switch_threshold=switch_threshold, add_threshold=add_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 s, sys: 1 s, total: 7 s\n",
      "Wall time: 5.47 s\n"
     ]
    }
   ],
   "source": [
    "cycles     = 3\n",
    "epochs     = 20\n",
    "batch_size = 1\n",
    "\n",
    "shuffle              = True  # Shuffle the active context dataset during training\n",
    "task_shuffle         = True  # Shuffle the contexts during training after first epoch\n",
    "initial_task_shuffle = True  # Shuffle the contexts before training\n",
    "\n",
    "verbose = 0 # Verbosity.Contexts\n",
    "\n",
    "# Benchmark the model\n",
    "%time task_map, context_map = train(model, x_train, y_train, cycles, epochs, task_shuffle, initial_task_shuffle, batch_size=batch_size, shuffle=shuffle, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0.00723264],\n",
      "       [0.93782854],\n",
      "       [0.9498591 ],\n",
      "       [0.00287011]], dtype=float32)\n",
      "array([[0.98832023],\n",
      "       [0.00237024],\n",
      "       [0.00483271],\n",
      "       [0.9900248 ]], dtype=float32)\n",
      "array([[0.00279853],\n",
      "       [0.00724164],\n",
      "       [0.0018844 ],\n",
      "       [0.99935496]], dtype=float32)\n",
      "array([[0.00274053],\n",
      "       [0.9950144 ],\n",
      "       [0.9936186 ],\n",
      "       [0.9973394 ]], dtype=float32)\n",
      "array([[0.98737764],\n",
      "       [0.0090552 ],\n",
      "       [0.00753856],\n",
      "       [0.00226769]], dtype=float32)\n",
      "array([[0.99796695],\n",
      "       [0.98994803],\n",
      "       [0.9983245 ],\n",
      "       [0.00225127]], dtype=float32)\n",
      "array([[9.9932086e-01],\n",
      "       [1.1155049e-04],\n",
      "       [9.9751312e-01],\n",
      "       [2.8488040e-04]], dtype=float32)\n",
      "array([[0.00635347],\n",
      "       [0.9942765 ],\n",
      "       [0.0063881 ],\n",
      "       [0.9984864 ]], dtype=float32)\n",
      "CPU times: user 594 ms, sys: 15.6 ms, total: 609 ms\n",
      "Wall time: 602 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'loss': 0.03144076094031334, 'binary_accuracy': 1.0},\n",
       " {'loss': 0.007247830741107464, 'binary_accuracy': 1.0},\n",
       " {'loss': 0.0031504775397479534, 'binary_accuracy': 1.0},\n",
       " {'loss': 0.004202056210488081, 'binary_accuracy': 1.0},\n",
       " {'loss': 0.007909111678600311, 'binary_accuracy': 1.0},\n",
       " {'loss': 0.004017171915620565, 'binary_accuracy': 1.0},\n",
       " {'loss': 0.0008914335048757493, 'binary_accuracy': 1.0},\n",
       " {'loss': 0.00500924326479435, 'binary_accuracy': 1.0}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1\n",
    "display_predictions = True\n",
    "verbose = 0\n",
    "\n",
    "%time evaluate(model, x_train, y_train, task_map, context_map, display_predictions, batch_size=batch_size, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
