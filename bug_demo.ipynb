{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Critical Bug Found\n",
    "\n",
    "There is a bug where gradients aren't applied the same way when using custom fit function. This could be causing the main struggles with MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Tensorflow and Keras layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from utils import idx_load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training images\n",
    "training_images = idx_load(\"datasets/mnist/train-images.idx3-ubyte\")\n",
    "training_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training labels\n",
    "training_labels = idx_load(\"datasets/mnist/train-labels.idx1-ubyte\")\n",
    "training_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the datasets\n",
    "training_images = training_images.reshape(len(training_images), 28*28) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bugged Model\n",
    "\n",
    "This model is a very minimal implementation of the basic training pattern. This reproduces a critical bug that is preventing the NTask model from properly learning MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BugModel(Model):\n",
    "    \n",
    "    def train_step(self, data):\n",
    "\n",
    "        x, y = data\n",
    "        \n",
    "        # Forward pass and apply gradients\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)\n",
    "            loss = self.loss(y, y_pred)\n",
    "            gradients = tape.gradient(loss, self.trainable_variables)\n",
    "            self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "            \n",
    "        # Metrics\n",
    "        for metric in self.metrics:\n",
    "            metric.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    \n",
    "    def fit(self, x_train, y_train, epochs=1, verbose=0, batch_size=32, use_real_fit=True):\n",
    "        if use_real_fit:\n",
    "            super(BugModel, self).fit(x_train, y_train, epochs=epochs, verbose=verbose, batch_size=batch_size)\n",
    "        else:\n",
    "            for epoch in range(epochs):\n",
    "                for batch in range(0, len(y_train), batch_size):\n",
    "                    x = x_train[batch:batch+batch_size]\n",
    "                    y = y_train[batch:batch+batch_size]\n",
    "                    self.train_step((x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x_train, y_train, epochs=1, batch_size=32, verbose=1, use_real_fit=True, seed=5):\n",
    "    # Set the random seed for all used libraries\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "    # Create the model\n",
    "    inp = Input((28*28,))\n",
    "    x = Dense(128, activation=\"relu\")(inp)\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = BugModel(inputs=inp, outputs=x)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        optimizer=tf.keras.optimizers.SGD(1e-4)\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, use_real_fit=use_real_fit, verbose=verbose)\n",
    "    \n",
    "    # Calculate and display the accuracy\n",
    "    result = (np.round(model(x_train)).astype(int).flatten() == y_train).sum()\n",
    "    print(f\"{result}/{len(y_train)}; Accuracy: {100*result/len(y_train):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST number is even\n",
    "x_train = training_images\n",
    "y_train = np.array([int(i % 2 == 0) for i in training_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1 4]\n",
      "[0 1 1 0 0 1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Verify on the first 10 the dataset seems correct...\n",
    "print(training_labels[:10])\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48394/60000; Accuracy: 80.66%\n"
     ]
    }
   ],
   "source": [
    "test(x_train, y_train, epochs=10, batch_size=64, verbose=0, use_real_fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30606/60000; Accuracy: 51.01%\n"
     ]
    }
   ],
   "source": [
    "test(x_train, y_train, epochs=10, batch_size=64, verbose=0, use_real_fit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
